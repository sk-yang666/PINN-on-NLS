{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20cdd684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import nn, optim \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import cycle\n",
    "from collections import Counter\n",
    "%matplotlib inline\n",
    "import random\n",
    "from torch.utils import data\n",
    "import os\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8e41b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dca358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x=pd.read_csv(\"data_x_new.csv\")\n",
    "data_t=pd.read_csv(\"data_t_new.csv\")\n",
    "data_xx=pd.read_csv(\"data_x_x.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "969f73bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "h10_x=data_x.iloc[:, [0]]#初值x,t\n",
    "h10_t=data_x.iloc[:, [1]]\n",
    "h10_R=data_x.iloc[:,[2]]#初值h实部\n",
    "h10_C=data_x.iloc[:,[3]]#初值h虚部\n",
    "hb_x1=data_t.iloc[:,[1]]#边值-5，t\n",
    "hb_t1=data_t.iloc[:,[0]]\n",
    "hb_x2=data_t.iloc[:,[2]]#边值5，t\n",
    "hb_t2=data_t.iloc[:,[0]]\n",
    "\n",
    "h20_x=data_x.iloc[:, [0]]#初值x,t\n",
    "h20_t=data_x.iloc[:, [1]]\n",
    "h20_R=data_x.iloc[:,[4]]#初值h实部\n",
    "h20_C=data_x.iloc[:,[5]]#初值h虚部\n",
    "\n",
    "h30_x=data_xx.iloc[:, [0]]\n",
    "h30_t=data_xx.iloc[:, [1]]\n",
    "h30_r1=data_xx.iloc[:, [2]]\n",
    "h30_c1=data_xx.iloc[:, [3]]\n",
    "h30_r2=data_xx.iloc[:, [4]]\n",
    "h30_c2=data_xx.iloc[:, [5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76bd3759",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_x['x']\n",
    "t = data_t['t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b2ca994",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, T = np.meshgrid(x,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc71aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf= np.hstack((X.flatten()[:,None], T.flatten()[:,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "950258e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_x=hf[:,[0]]\n",
    "hf_t=hf[:,[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78ff78e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train10_x,test10_x,train10_t,test10_t,train10_r,test10_r,train10_c,test10_c,trainb_x1,testb_x1,trainb_t1,testb_t1,trainb_x2,testb_x2,trainb_t2,testb_t2,train20_r,test20_r,train20_c,test20_c = train_test_split(h10_x,h10_t,h10_R,h10_C,hb_x1,hb_t1,hb_x2,hb_t2,h20_R,h20_C,test_size=0.2)\n",
    "\n",
    "train30_x,test30_x,train30_t,test30_t,train30_r1,test30_r1,train30_c1,test30_c1,train30_r2,test30_r2,train30_c2,test30_c2=train_test_split(h30_x,h30_t,h30_r1,h30_c1,h30_r2,h30_c2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8301e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainu_x, testu_x, trainu_t, testu_t = train_test_split(hf_x, hf_t, test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68c1b3f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train10_x=torch.from_numpy(train10_x.to_numpy()).float()\n",
    "train10_t=torch.from_numpy(train10_t.to_numpy()).float()\n",
    "\n",
    "train10_r=torch.from_numpy(train10_r.to_numpy()).float()\n",
    "train10_c=torch.from_numpy(train10_c.to_numpy()).float()\n",
    "\n",
    "trainb_x1=torch.from_numpy(trainb_x1.to_numpy()).float()\n",
    "trainb_t1=torch.from_numpy(trainb_t1.to_numpy()).float()\n",
    "trainb_x2=torch.from_numpy(trainb_x2.to_numpy()).float()\n",
    "trainb_t2=torch.from_numpy(trainb_t2.to_numpy()).float()\n",
    "\n",
    "# train20_x=torch.from_numpy(train20_x.to_numpy()).float()\n",
    "# train20_t=torch.from_numpy(train20_t.to_numpy()).float()\n",
    "train20_r=torch.from_numpy(train20_r.to_numpy()).float()\n",
    "train20_c=torch.from_numpy(train20_c.to_numpy()).float()\n",
    "\n",
    "\n",
    "train30_x=torch.from_numpy(train30_x.to_numpy()).float()\n",
    "train30_t=torch.from_numpy(train30_t.to_numpy()).float()\n",
    "train30_r1=torch.from_numpy(train30_r1.to_numpy()).float()\n",
    "train30_c1=torch.from_numpy(train30_c1.to_numpy()).float()\n",
    "train30_r2=torch.from_numpy(train30_r2.to_numpy()).float()\n",
    "train30_c2=torch.from_numpy(train30_c2.to_numpy()).float()\n",
    "\n",
    "trainu_x=torch.from_numpy(trainu_x).float()\n",
    "trainu_t=torch.from_numpy(trainu_t).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2e60ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test10_x=torch.from_numpy(test10_x.to_numpy()).float()\n",
    "test10_t=torch.from_numpy(test10_t.to_numpy()).float()\n",
    "test10_r=torch.from_numpy(test10_r.to_numpy()).float()\n",
    "test10_c=torch.from_numpy(test10_c.to_numpy()).float()\n",
    "\n",
    "testb_x1=torch.from_numpy(testb_x1.to_numpy()).float()\n",
    "testb_t1=torch.from_numpy(testb_t1.to_numpy()).float()\n",
    "testb_x2=torch.from_numpy(testb_x2.to_numpy()).float()\n",
    "testb_t2=torch.from_numpy(testb_t2.to_numpy()).float()\n",
    "\n",
    "# test20_x=torch.from_numpy(test20_x.to_numpy()).float()\n",
    "# test20_t=torch.from_numpy(test20_t.to_numpy()).float()\n",
    "test20_r=torch.from_numpy(test20_r.to_numpy()).float()\n",
    "test20_c=torch.from_numpy(test20_c.to_numpy()).float()\n",
    "\n",
    "testu_x=torch.from_numpy(testu_x).float()\n",
    "testu_t=torch.from_numpy(testu_t).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20c0aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7b860f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2, 60),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(60, 60),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(60, 60),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(60, 60),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(60, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f5e4528",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsInformedNN():\n",
    "    def __init__(self, u10_x, u10_t, u10_r, u10_c, ub_x1, ub_t1, ub_x2, ub_t2, u20_r, u20_c, uf_x, uf_t,u30_x,u30_t,u30_r1,u30_c1,u30_r2,u30_c2):\n",
    "        self.u10_x = torch.tensor(u10_x, requires_grad=True).float().to(device)\n",
    "        self.u10_t = torch.tensor(u10_t, requires_grad=True).float().to(device)\n",
    "        self.u10_r = torch.tensor(u10_r, requires_grad=True).float().to(device)\n",
    "        self.u10_c = torch.tensor(u10_c, requires_grad=True).float().to(device)\n",
    "        \n",
    "        self.ub_x1 = torch.tensor(ub_x1, requires_grad=True).float().to(device)\n",
    "        self.ub_x2 = torch.tensor(ub_x2, requires_grad=True).float().to(device)\n",
    "        self.ub_t1 = torch.tensor(ub_t1, requires_grad=True).float().to(device)\n",
    "        self.ub_t2 = torch.tensor(ub_t2, requires_grad=True).float().to(device)\n",
    "        \n",
    "#         self.u20_x = u20_x.clone().detach().requires_grad_(True).float().to(device)\n",
    "#         self.u20_t = torch.tensor(u20_t, requires_grad=True).float().to(device)\n",
    "        self.u20_r = torch.tensor(u20_r, requires_grad=True).float().to(device)\n",
    "        self.u20_c = torch.tensor(u20_c, requires_grad=True).float().to(device)\n",
    "        \n",
    "        self.u30_x = torch.tensor(u30_x, requires_grad=True).float().to(device)\n",
    "        self.u30_t = torch.tensor(u30_t, requires_grad=True).float().to(device)\n",
    "        self.u30_r1 = torch.tensor(u30_r1, requires_grad=True).float().to(device)\n",
    "        self.u30_c1 = torch.tensor(u30_c1, requires_grad=True).float().to(device)\n",
    "        self.u30_r2 = torch.tensor(u30_r2, requires_grad=True).float().to(device)\n",
    "        self.u30_c2 = torch.tensor(u30_c2, requires_grad=True).float().to(device)\n",
    "      \n",
    "        \n",
    "        self.uf_x = torch.tensor(uf_x,requires_grad=True).float().to(device)\n",
    "        self.uf_t = torch.tensor(uf_t,requires_grad=True).float().to(device)\n",
    "        \n",
    "        self.lambda_1 = torch.tensor([0.9], requires_grad=True).to(device)\n",
    "        self.lambda_1 = torch.nn.Parameter(self.lambda_1)\n",
    "        \n",
    "        self.lambda_2 = torch.tensor([2.3], requires_grad=True).to(device)\n",
    "        self.lambda_2 = torch.nn.Parameter(self.lambda_2)\n",
    "        \n",
    "        self.dnn = DNN().to(device)\n",
    "        self.optimizer = torch.optim.Adam([\n",
    "            {'params':self.dnn.parameters()},\n",
    "            {'params': [self.lambda_1], 'lr': 0.000206},\n",
    "            {'params': [self.lambda_2], 'lr': 0.000105}\n",
    "        ],lr=0.012 )\n",
    "        \n",
    "        self.iter = 0\n",
    "    \n",
    "        self.losshistory=[]\n",
    "    def net_u(self, x, t):  \n",
    "        u1 = torch.unsqueeze(self.dnn(torch.cat([x, t], dim=1))[:,0],1)\n",
    "        v1 = torch.unsqueeze(self.dnn(torch.cat([x, t], dim=1))[:,1],1)\n",
    "        u2 = torch.unsqueeze(self.dnn(torch.cat([x, t], dim=1))[:,2],1)\n",
    "        v2 = torch.unsqueeze(self.dnn(torch.cat([x, t], dim=1))[:,3],1)\n",
    "        return u1, v1, u2, v2\n",
    "\n",
    "    \n",
    "    def net_f(self, x, t):\n",
    "        \"\"\" The pytorch autograd version of calculating residual \"\"\"\n",
    "        beta=1\n",
    "        lambda_1 = self.lambda_1\n",
    "        lambda_2 = self.lambda_2\n",
    "        lambda_3 = -1\n",
    "        lambda_4 = 0\n",
    "        u1, v1,u2, v2= self.net_u(x, t)\n",
    "        \n",
    "        u1_t = torch.autograd.grad(\n",
    "            u1, t, \n",
    "            grad_outputs=torch.ones_like(u1),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        u1_x = torch.autograd.grad(\n",
    "            u1, x, \n",
    "            grad_outputs=torch.ones_like(u1),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        u1_xx = torch.autograd.grad(\n",
    "            u1_x, x, \n",
    "            grad_outputs=torch.ones_like(u1_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        v1_t = torch.autograd.grad(\n",
    "            v1, t, \n",
    "            grad_outputs=torch.ones_like(v1),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        v1_x = torch.autograd.grad(\n",
    "            v1, x, \n",
    "            grad_outputs=torch.ones_like(v1),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        v1_xx = torch.autograd.grad(\n",
    "            v1_x, x, \n",
    "            grad_outputs=torch.ones_like(v1_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        \n",
    "        u2_t = torch.autograd.grad(\n",
    "            u2, t, \n",
    "            grad_outputs=torch.ones_like(u2),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        u2_x = torch.autograd.grad(\n",
    "            u2, x, \n",
    "            grad_outputs=torch.ones_like(u2),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        u2_xx = torch.autograd.grad(\n",
    "            u2_x, x, \n",
    "            grad_outputs=torch.ones_like(u2_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        v2_t = torch.autograd.grad(\n",
    "            v2, t, \n",
    "            grad_outputs=torch.ones_like(v2),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        v2_x = torch.autograd.grad(\n",
    "            v2, x, \n",
    "            grad_outputs=torch.ones_like(v2),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        v2_xx = torch.autograd.grad(\n",
    "            v2_x, x, \n",
    "            grad_outputs=torch.ones_like(v2_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        f_u1 = (\n",
    "            v1_t + u1_xx\n",
    "        + lambda_1*u1*(u1**2 + v1**2) + lambda_2*u1*(u2**2 + v2**2) + lambda_3*(u1*(u2**2 - v2**2) + 2*u2*v1*v2) + lambda_4*(u2*(u1**2 - v1**2) + 2*u1*v1*v2)\n",
    "    )\n",
    "\n",
    "        f_v1 = (\n",
    "                -u1_t + v1_xx\n",
    "            + lambda_1*v1*(u1**2 + v1**2) + lambda_2*v1*(u2**2 + v2**2) - lambda_3*(v1*(u2**2 - v2**2) - 2*u1*u2*v2) - lambda_4*(v2*(u1**2 - v1**2) - 2*u1*u2*v1)\n",
    "        )\n",
    "\n",
    "        f_u2 = (\n",
    "                v2_t + beta*u2_xx\n",
    "            + lambda_1*u2*(u2**2 + v2**2) + lambda_2*u2*(u1**2 + v1**2) + lambda_3*(u2*(u1**2 - v1**2) + 2*u1*v2*v1) + lambda_4*(u1*(u2**2 - v2**2) + 2*u2*v2*v1)\n",
    "        )\n",
    "\n",
    "        f_v2 = (\n",
    "                -u2_t + beta*v2_xx\n",
    "            + lambda_1*v2*(u2**2 + v2**2) + lambda_2*v2*(u1**2 + v1**2) - lambda_3*(v2*(u1**2 - v1**2) - 2*u2*u1*v1) - lambda_4*(v1*(u2**2 - v2**2) - 2*u2*u1*v2)\n",
    "        )\n",
    "        a=u1_x\n",
    "        b=v1_x\n",
    "        c=u2_x\n",
    "        d=v2_x\n",
    "        return f_u1, f_v1, f_u2, f_v2, a, b, c, d\n",
    "     \n",
    "    def loss_func(self):\n",
    "        for self.iter in tqdm(range(20000)):\n",
    "            torch.cuda.empty_cache()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            u10_pred, v10_pred, u20_pred, v20_pred = self.net_u(self.u10_x,self.u10_t)\n",
    "            u30_pred1, v30_pred1, u30_pred2, v30_pred2 = self.net_u(self.u30_x,self.u30_t)\n",
    "            u1b_pred1, v1b_pred1, u2b_pred1, v2b_pred1 = self.net_u(self.ub_x1,self.ub_t1)\n",
    "            u1b_pred2, v1b_pred2, u2b_pred2, v2b_pred2 = self .net_u(self.ub_x2,self.ub_t2)\n",
    "            \n",
    "            \n",
    "            a1,b1,c1,d1,u1bx_pred1, v1bx_pred1,u2bx_pred1, v2bx_pred1 = self.net_f(self.ub_x1,self.ub_t1)\n",
    "            a2,b2,c2,d2,u1bx_pred2, v1bx_pred2,u2bx_pred2, v2bx_pred2 = self.net_f(self.ub_x2,self.ub_t2)\n",
    "            \n",
    "            f_predu1, f_predv1, f_predu2, f_predv2,a1,b1,c1,d1 = self.net_f(self.uf_x,self.uf_t)\n",
    "            \n",
    "            loss_u0 = torch.mean((self.u10_r - u10_pred) ** 2)+torch.mean((self.u10_c - v10_pred) ** 2)+torch.mean((self.u20_r - u20_pred) ** 2)+torch.mean((self.u20_c - v20_pred) ** 2)\n",
    "            loss_ub = torch.mean((u1b_pred1 - u1b_pred2) ** 2)+torch.mean((v1b_pred1 - v1b_pred2) ** 2)+torch.mean((u2b_pred1 - u2b_pred2) ** 2)+torch.mean((v2b_pred1 - v2b_pred2) ** 2)\n",
    "            loss_ubx = torch.mean((u1bx_pred1 - u1bx_pred2) ** 2)+torch.mean((v1bx_pred1 - v1bx_pred2) ** 2)+torch.mean((u2bx_pred1 - u2bx_pred2) ** 2)+torch.mean((v2bx_pred1 - v2bx_pred2) ** 2)\n",
    "            loss_f = torch.mean(f_predu1 ** 2)+torch.mean(f_predv1 ** 2)+torch.mean(f_predu2 ** 2)+torch.mean(f_predv2 ** 2)\n",
    "            loss_u1=torch.mean((self.u30_r1 - u30_pred1) ** 2)+torch.mean((self.u30_c1 - v30_pred1) ** 2)+torch.mean((self.u30_r2 - u30_pred2) ** 2)+torch.mean((self.u30_c2 - v30_pred2) ** 2)\n",
    "            \n",
    "            loss = loss_f+loss_u0 + loss_ub + loss_ubx+loss_u1\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            self.losshistory.append(loss.clone().detach().cpu())\n",
    "            \n",
    "            self.iter += 1\n",
    "            with torch.no_grad():\n",
    "                if self.iter % 500 == 0:\n",
    "                    print('Iter %d, Loss: %.5e, Loss_u0: %.5e, Loss_ub: %.5e, Loss_ubx: %.5e, Loss_f: %.5e, Loss_u1: %.5e, lambda1: %.5e, lambda2: %.5e' % (self.iter, loss.item(), loss_u0.item(), loss_ub.item(), loss_ubx.item(), loss_f.item(), loss_u1.item(), self.lambda_1,self.lambda_2))\n",
    "        return float(loss)\n",
    "        \n",
    " \n",
    "    def train(self):\n",
    "        self.dnn.train()\n",
    "                \n",
    "        # Backward and optimize\n",
    "        self.optimizer.step(self.loss_func)\n",
    "        \n",
    "    def predict1(self, X, Y):\n",
    "        x = torch.tensor(X, requires_grad=True).float().to(device)\n",
    "        t = torch.tensor(Y, requires_grad=True).float().to(device)\n",
    "\n",
    "        self.dnn.eval()\n",
    "        u1, v1 , u2, v2= self.net_u(x, t)\n",
    "        u1 = u1.detach().cpu().numpy()\n",
    "        v1 = v1.detach().cpu().numpy()\n",
    "        u2 = u2.detach().cpu().numpy()\n",
    "        v2 = v2.detach().cpu().numpy()\n",
    "        return u1, v1, u2, v2\n",
    "    \n",
    "    def predict2(self, X, Y):\n",
    "        x = torch.tensor(X, requires_grad=True).float().to(device)\n",
    "        t = torch.tensor(Y, requires_grad=True).float().to(device)\n",
    "\n",
    "        self.dnn.eval()\n",
    "        f1, f2, f3, f4, a, b, c, d = self.net_f(x, t)\n",
    "        f1 = f1.detach().cpu().numpy()\n",
    "        f2 = f2.detach().cpu().numpy()\n",
    "        f3 = f3.detach().cpu().numpy()\n",
    "        f4 = f4.detach().cpu().numpy()\n",
    "        return  f1, f2, f3, f4, a, b, c, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08905a55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_19900\\2281346290.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.u10_x = torch.tensor(u10_x, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_19900\\2281346290.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.u10_t = torch.tensor(u10_t, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_19900\\2281346290.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.u10_r = torch.tensor(u10_r, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_19900\\2281346290.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.u10_c = torch.tensor(u10_c, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_19900\\2281346290.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.ub_x1 = torch.tensor(ub_x1, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_19900\\2281346290.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.ub_x2 = torch.tensor(ub_x2, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_19900\\2281346290.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.ub_t1 = torch.tensor(ub_t1, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_19900\\2281346290.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.ub_t2 = torch.tensor(ub_t2, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_19900\\2281346290.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.u20_r = torch.tensor(u20_r, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_19900\\2281346290.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.u20_c = torch.tensor(u20_c, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_19900\\2281346290.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.u30_x = torch.tensor(u30_x, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_19900\\2281346290.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.u30_t = torch.tensor(u30_t, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_19900\\2281346290.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.u30_r1 = torch.tensor(u30_r1, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_19900\\2281346290.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.u30_c1 = torch.tensor(u30_c1, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_19900\\2281346290.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.u30_r2 = torch.tensor(u30_r2, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_19900\\2281346290.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.u30_c2 = torch.tensor(u30_c2, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_19900\\2281346290.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.uf_x = torch.tensor(uf_x,requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_19900\\2281346290.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.uf_t = torch.tensor(uf_t,requires_grad=True).float().to(device)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = PhysicsInformedNN(train10_x, train10_t, train10_r, train10_c, \n",
    "                          trainb_x1, trainb_t1, trainb_x2, trainb_t2,\n",
    "                        train20_r, train20_c, trainu_x, trainu_t,\n",
    "                         train30_x,train30_t, train30_r1, train30_c1,train30_r2,train30_c2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7626fd4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 500/20000 [01:43<1:00:11,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 500, Loss: 1.42629e-01, Loss_u0: 1.40969e-02, Loss_ub: 1.93318e-05, Loss_ubx: 2.80924e-05, Loss_f: 3.59358e-02, Loss_u1: 9.25493e-02, lambda1: 9.62413e-01, lambda2: 2.27511e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1001/20000 [03:19<59:13,  5.35it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1000, Loss: 1.30046e-01, Loss_u0: 1.04679e-02, Loss_ub: 3.35914e-05, Loss_ubx: 4.71676e-05, Loss_f: 3.44926e-02, Loss_u1: 8.50046e-02, lambda1: 9.93006e-01, lambda2: 2.24109e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1500/20000 [04:56<56:25,  5.47it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1500, Loss: 1.00198e-01, Loss_u0: 3.02101e-03, Loss_ub: 8.52247e-06, Loss_ubx: 1.17664e-05, Loss_f: 2.76775e-02, Loss_u1: 6.94791e-02, lambda1: 1.00855e+00, lambda2: 2.21445e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2001/20000 [06:31<57:10,  5.25it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2000, Loss: 9.23980e-02, Loss_u0: 1.98133e-03, Loss_ub: 1.14429e-04, Loss_ubx: 7.01079e-06, Loss_f: 2.11555e-02, Loss_u1: 6.91397e-02, lambda1: 1.00926e+00, lambda2: 2.20352e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2501/20000 [08:08<58:30,  4.99it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2500, Loss: 1.70765e-01, Loss_u0: 6.63618e-03, Loss_ub: 2.37114e-04, Loss_ubx: 2.57736e-05, Loss_f: 5.69292e-02, Loss_u1: 1.06937e-01, lambda1: 1.00914e+00, lambda2: 2.19436e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3001/20000 [09:44<57:07,  4.96it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3000, Loss: 7.66292e-02, Loss_u0: 1.33913e-03, Loss_ub: 1.78104e-05, Loss_ubx: 8.38572e-06, Loss_f: 1.63932e-02, Loss_u1: 5.88707e-02, lambda1: 1.00100e+00, lambda2: 2.18547e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3501/20000 [11:20<53:39,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3500, Loss: 1.43260e-01, Loss_u0: 7.51115e-03, Loss_ub: 7.77522e-06, Loss_ubx: 8.15555e-06, Loss_f: 3.52724e-02, Loss_u1: 1.00460e-01, lambda1: 1.01936e+00, lambda2: 2.17605e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4001/20000 [12:57<50:11,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4000, Loss: 1.07845e-01, Loss_u0: 2.20442e-03, Loss_ub: 1.70665e-06, Loss_ubx: 1.90849e-06, Loss_f: 2.86345e-02, Loss_u1: 7.70025e-02, lambda1: 1.03003e+00, lambda2: 2.14863e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4501/20000 [14:33<48:35,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4500, Loss: 1.15131e-01, Loss_u0: 4.57430e-03, Loss_ub: 1.58557e-06, Loss_ubx: 1.23533e-06, Loss_f: 4.34896e-02, Loss_u1: 6.70645e-02, lambda1: 1.03407e+00, lambda2: 2.12760e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5001/20000 [16:09<47:49,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 5000, Loss: 7.98843e-02, Loss_u0: 1.41881e-03, Loss_ub: 1.83789e-06, Loss_ubx: 2.38366e-06, Loss_f: 1.87766e-02, Loss_u1: 5.96847e-02, lambda1: 1.02607e+00, lambda2: 2.11523e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 5500/20000 [17:44<46:38,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 5500, Loss: 6.62154e-02, Loss_u0: 1.30027e-03, Loss_ub: 1.40961e-07, Loss_ubx: 3.41181e-07, Loss_f: 1.82682e-02, Loss_u1: 4.66464e-02, lambda1: 1.01434e+00, lambda2: 2.10221e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6001/20000 [19:20<45:13,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 6000, Loss: 2.19528e-01, Loss_u0: 9.68309e-03, Loss_ub: 4.55952e-05, Loss_ubx: 2.62524e-05, Loss_f: 4.48090e-02, Loss_u1: 1.64964e-01, lambda1: 1.00813e+00, lambda2: 2.09466e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 6500/20000 [20:56<43:20,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 6500, Loss: 1.08776e-01, Loss_u0: 2.64823e-03, Loss_ub: 7.24582e-07, Loss_ubx: 1.28937e-06, Loss_f: 2.44297e-02, Loss_u1: 8.16964e-02, lambda1: 1.03080e+00, lambda2: 2.09292e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7001/20000 [22:32<41:59,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 7000, Loss: 1.09322e-01, Loss_u0: 1.84795e-03, Loss_ub: 5.19839e-07, Loss_ubx: 1.17404e-06, Loss_f: 2.61531e-02, Loss_u1: 8.13191e-02, lambda1: 1.03580e+00, lambda2: 2.08066e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 7501/20000 [24:08<39:09,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 7500, Loss: 8.48196e-02, Loss_u0: 2.35427e-03, Loss_ub: 2.26548e-07, Loss_ubx: 3.06794e-07, Loss_f: 2.71458e-02, Loss_u1: 5.53190e-02, lambda1: 1.03398e+00, lambda2: 2.06799e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8001/20000 [25:44<39:07,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 8000, Loss: 6.66019e-02, Loss_u0: 1.46261e-03, Loss_ub: 2.69386e-07, Loss_ubx: 1.77969e-07, Loss_f: 1.90260e-02, Loss_u1: 4.61128e-02, lambda1: 1.02820e+00, lambda2: 2.05360e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 8500/20000 [27:19<38:45,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 8500, Loss: 5.42747e-01, Loss_u0: 1.92124e-01, Loss_ub: 2.73856e-15, Loss_ubx: 2.62149e-14, Loss_f: 7.22264e-02, Loss_u1: 2.78396e-01, lambda1: 9.98875e-01, lambda2: 2.04994e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9001/20000 [28:57<35:09,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 9000, Loss: 2.80237e-01, Loss_u0: 2.05255e-02, Loss_ub: 6.00371e-14, Loss_ubx: 3.67171e-13, Loss_f: 4.63051e-02, Loss_u1: 2.13406e-01, lambda1: 9.81481e-01, lambda2: 2.04927e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 9500/20000 [31:30<1:10:11,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 9500, Loss: 2.01733e-01, Loss_u0: 4.70708e-03, Loss_ub: 4.97170e-07, Loss_ubx: 1.19199e-07, Loss_f: 3.07869e-02, Loss_u1: 1.66239e-01, lambda1: 9.91483e-01, lambda2: 2.06692e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10001/20000 [33:43<32:41,  5.10it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10000, Loss: 1.71732e-01, Loss_u0: 2.70696e-03, Loss_ub: 2.37177e-15, Loss_ubx: 3.65177e-14, Loss_f: 2.32348e-02, Loss_u1: 1.45791e-01, lambda1: 1.01428e+00, lambda2: 2.08235e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 10500/20000 [37:17<1:08:17,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10500, Loss: 1.57445e-01, Loss_u0: 5.29581e-03, Loss_ub: 7.85772e-07, Loss_ubx: 1.11748e-06, Loss_f: 4.64661e-02, Loss_u1: 1.05681e-01, lambda1: 1.02740e+00, lambda2: 2.08630e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11000/20000 [40:41<1:01:29,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 11000, Loss: 6.63316e-01, Loss_u0: 3.48716e-01, Loss_ub: 0.00000e+00, Loss_ubx: 1.61787e-20, Loss_f: 1.01335e-02, Loss_u1: 3.04466e-01, lambda1: 1.03320e+00, lambda2: 2.08899e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 11500/20000 [44:21<1:08:01,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 11500, Loss: 6.96878e-01, Loss_u0: 3.86806e-01, Loss_ub: 0.00000e+00, Loss_ubx: 0.00000e+00, Loss_f: 1.60738e-03, Loss_u1: 3.08465e-01, lambda1: 1.03344e+00, lambda2: 2.08910e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12000/20000 [48:04<46:33,  2.86it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 12000, Loss: 6.88636e-01, Loss_u0: 3.79656e-01, Loss_ub: 9.30096e-06, Loss_ubx: 9.80042e-06, Loss_f: 3.76257e-03, Loss_u1: 3.05199e-01, lambda1: 1.03366e+00, lambda2: 2.08979e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 12500/20000 [51:46<1:01:39,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 12500, Loss: 6.98658e-01, Loss_u0: 3.86960e-01, Loss_ub: 0.00000e+00, Loss_ubx: 0.00000e+00, Loss_f: 1.40392e-06, Loss_u1: 3.11696e-01, lambda1: 1.03367e+00, lambda2: 2.08980e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13000/20000 [54:35<34:45,  3.36it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 13000, Loss: 6.98658e-01, Loss_u0: 3.86960e-01, Loss_ub: 0.00000e+00, Loss_ubx: 0.00000e+00, Loss_f: 1.40393e-06, Loss_u1: 3.11696e-01, lambda1: 1.03367e+00, lambda2: 2.08980e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 13500/20000 [58:06<47:47,  2.27it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 13500, Loss: 6.98658e-01, Loss_u0: 3.86960e-01, Loss_ub: 0.00000e+00, Loss_ubx: 0.00000e+00, Loss_f: 1.40381e-06, Loss_u1: 3.11696e-01, lambda1: 1.03362e+00, lambda2: 2.08980e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14000/20000 [1:01:45<34:46,  2.88it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 14000, Loss: 6.98658e-01, Loss_u0: 3.86960e-01, Loss_ub: 0.00000e+00, Loss_ubx: 0.00000e+00, Loss_f: 1.40366e-06, Loss_u1: 3.11696e-01, lambda1: 1.03356e+00, lambda2: 2.08980e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 14500/20000 [1:05:25<48:23,  1.89it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 14500, Loss: 6.98658e-01, Loss_u0: 3.86960e-01, Loss_ub: 0.00000e+00, Loss_ubx: 0.00000e+00, Loss_f: 1.40350e-06, Loss_u1: 3.11696e-01, lambda1: 1.03350e+00, lambda2: 2.08980e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15000/20000 [1:08:37<20:26,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 15000, Loss: 6.98658e-01, Loss_u0: 3.86960e-01, Loss_ub: 0.00000e+00, Loss_ubx: 0.00000e+00, Loss_f: 1.40334e-06, Loss_u1: 3.11696e-01, lambda1: 1.03344e+00, lambda2: 2.08980e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 15500/20000 [1:11:34<18:41,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 15500, Loss: 6.98658e-01, Loss_u0: 3.86960e-01, Loss_ub: 0.00000e+00, Loss_ubx: 0.00000e+00, Loss_f: 1.40313e-06, Loss_u1: 3.11696e-01, lambda1: 1.03336e+00, lambda2: 2.08980e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16000/20000 [1:13:38<16:26,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 16000, Loss: 6.98658e-01, Loss_u0: 3.86960e-01, Loss_ub: 0.00000e+00, Loss_ubx: 0.00000e+00, Loss_f: 1.40282e-06, Loss_u1: 3.11696e-01, lambda1: 1.03324e+00, lambda2: 2.08980e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 16500/20000 [1:15:42<14:17,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 16500, Loss: 6.98658e-01, Loss_u0: 3.86960e-01, Loss_ub: 0.00000e+00, Loss_ubx: 0.00000e+00, Loss_f: 1.40245e-06, Loss_u1: 3.11696e-01, lambda1: 1.03311e+00, lambda2: 2.08980e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17000/20000 [1:17:44<11:59,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 17000, Loss: 6.98658e-01, Loss_u0: 3.86960e-01, Loss_ub: 0.00000e+00, Loss_ubx: 0.00000e+00, Loss_f: 1.40197e-06, Loss_u1: 3.11696e-01, lambda1: 1.03293e+00, lambda2: 2.08980e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 17500/20000 [1:19:48<09:29,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 17500, Loss: 6.98658e-01, Loss_u0: 3.86960e-01, Loss_ub: 0.00000e+00, Loss_ubx: 0.00000e+00, Loss_f: 1.40134e-06, Loss_u1: 3.11696e-01, lambda1: 1.03269e+00, lambda2: 2.08980e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18000/20000 [1:21:50<08:40,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 18000, Loss: 6.98658e-01, Loss_u0: 3.86960e-01, Loss_ub: 0.00000e+00, Loss_ubx: 0.00000e+00, Loss_f: 1.40052e-06, Loss_u1: 3.11696e-01, lambda1: 1.03239e+00, lambda2: 2.08980e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 18500/20000 [1:23:58<06:20,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 18500, Loss: 6.98658e-01, Loss_u0: 3.86985e-01, Loss_ub: 0.00000e+00, Loss_ubx: 0.00000e+00, Loss_f: 1.38983e-06, Loss_u1: 3.11672e-01, lambda1: 1.03200e+00, lambda2: 2.08980e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19000/20000 [1:26:04<04:20,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 19000, Loss: 6.98659e-01, Loss_u0: 3.86962e-01, Loss_ub: 0.00000e+00, Loss_ubx: 0.00000e+00, Loss_f: 1.39788e-06, Loss_u1: 3.11695e-01, lambda1: 1.03151e+00, lambda2: 2.08980e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 19500/20000 [1:28:12<01:56,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 19500, Loss: 6.98658e-01, Loss_u0: 3.86973e-01, Loss_ub: 0.00000e+00, Loss_ubx: 0.00000e+00, Loss_f: 1.39165e-06, Loss_u1: 3.11684e-01, lambda1: 1.03087e+00, lambda2: 2.08980e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [1:30:19<00:00,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20000, Loss: 6.98658e-01, Loss_u0: 3.86950e-01, Loss_ub: 0.00000e+00, Loss_ubx: 0.00000e+00, Loss_f: 1.39788e-06, Loss_u1: 3.11706e-01, lambda1: 1.03006e+00, lambda2: 2.08980e+00\n",
      "Wall time: 1h 30min 19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.losshistory=[]            \n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "117e3d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c715ecc850>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABJMElEQVR4nO3de1yUZf4//tdwGhQBRRRFUdE0LcwU07TMQ0mhWf3aXS37ppn2yTU1M9ti3VJbN9wOrp20tjRqM3PtYLW6KW4qKlqB4AnPoiDHUBlOMsDM9fsDGWeYM8zMPXPfr+fjMQ/lvq977uuae2bu91xHlRBCgIiIiEgiflJngIiIiJSNwQgRERFJisEIERERSYrBCBEREUmKwQgRERFJisEIERERSYrBCBEREUmKwQgRERFJKkDqDDhCr9ejsLAQoaGhUKlUUmeHiIiIHCCEQGVlJaKjo+HnZ73+wyeCkcLCQsTExEidDSIiImqB/Px8dO/e3ep+nwhGQkNDATQWJiwsTOLcEBERkSMqKioQExNjuI9b4xPBSFPTTFhYGIMRIiIiH2Ovi4XTHVjT0tIwadIkREdHQ6VSYfPmzXaP0Wq1WLx4MXr27Am1Wo0+ffpg3bp1zp6aiIiIZMjpmpHq6moMGjQIM2bMwO9+9zuHjpk8eTJKSkqwdu1a3HDDDSgtLUVDQ4PTmSUiIiL5cToYSUxMRGJiosPpf/zxR+zevRvnzp1DREQEAKBXr17OnpaIiIhkyu3zjHz//fcYOnQoXn/9dXTr1g39+vXDokWLcPXqVXefmoiIiHyA2zuwnjt3Dnv37kVwcDC+/fZblJWVYc6cObh8+bLVfiNarRZardbwd0VFhbuzSURERBJxe82IXq+HSqXC+vXrMWzYMEyYMAErV65ESkqK1dqR5ORkhIeHGx6cY4SIiEi+3B6MdO3aFd26dUN4eLhh24ABAyCEwMWLFy0ek5SUBI1GY3jk5+e7O5tEREQkEbcHI3fccQcKCwtRVVVl2Hbq1Cn4+flZnY1NrVYb5hTh3CJERETy5nQwUlVVhezsbGRnZwMAcnNzkZ2djby8PACNtRrTpk0zpJ86dSo6duyIGTNmICcnB2lpaXjhhRfw5JNPok2bNq4pBREREfksp4ORjIwMDB48GIMHDwYALFy4EIMHD8Yrr7wCACgqKjIEJgDQrl07pKamory8HEOHDsVjjz2GSZMm4Z133nFREYiIiMiXqYQQQupM2FNRUYHw8HBoNBo22RAREfkIR+/fbu8zQkRERGQLgxGy6XRJJT7ecw7aBp3UWSEiIpnyiVV7STrj/5EGAKip02H+3X0lzg0REckRa0bIIYfyy6XOAhERyRSDESIiIpIUgxEiIiKSFIMRIiIikhSDESIiIpIUgxEiIiKSFIMRIiIikhSDESIiIpIUgxEiIiKSFIMRIiIikhSDESIiIpIUgxFyiJA6A0REJFsMRoiIiEhSDEaIiIhIUgxGiIiISFIMRoiIiEhSDEbIISqpM0BERLLFYISIiIgkxWCEiIiIJMVghIiIiCTFYISIiIgkxWCEiIiIJMVghIiIiCTFYIQcwrVpiIjIXRiMEBERkaQYjBAREZGkGIwQERGRpBiMEBERkaQYjBAREZGkGIwQERGRpBiMEBERkaScDkbS0tIwadIkREdHQ6VSYfPmzQ4fu2/fPgQEBODWW2919rREREQkU04HI9XV1Rg0aBDee+89p47TaDSYNm0a7r77bmdPSURERDIW4OwBiYmJSExMdPpETz/9NKZOnQp/f3+nalPIO6ikzgA5LaewAuFtA9GtfRups0JEZJNH+ox88sknOHv2LJYsWeJQeq1Wi4qKCpMHETmusPwqJryzB3es+EnqrBAR2eX2YOT06dN46aWXsH79egQEOFYRk5ycjPDwcMMjJibGzbkke7g2jW85WVIpdRaIiBzm1mBEp9Nh6tSpWLZsGfr16+fwcUlJSdBoNIZHfn6+G3NJREREUnK6z4gzKisrkZGRgaysLMydOxcAoNfrIYRAQEAAtm/fjnHjxpkdp1aroVar3Zk1IiIi8hJuDUbCwsJw5MgRk22rV6/GTz/9hK+++gqxsbHuPD0RERH5AKeDkaqqKpw5c8bwd25uLrKzsxEREYEePXogKSkJBQUF+Oyzz+Dn54e4uDiT4zt37ozg4GCz7URERKRMTgcjGRkZGDt2rOHvhQsXAgCmT5+OlJQUFBUVIS8vz3U5JCIiIllzOhgZM2YMhLA+tiIlJcXm8UuXLsXSpUudPS0RERHJFNemIZIhTlJHRL6EwQgRERFJisEIERERSYrBCBEREUmKwQgRERFJisEIOcTWCCoiIqLWYDBCREREkmIwQg5RqThY1JfwehGRL2EwQkRERJJiMEIkQ+zjQ0S+hMEIERERSYrBCBEREUmKwQgRERFJisEIERERSYrBCJEMcWgvEfkSBiNEREQkKQYj5BAOFSUiIndhMEJERESSYjBCREREkmIwQkRERJJiMEJERESSYjBCREREkmIwQiRDnGWEiHwJgxEiIiKSFIMRcghn9CQiIndhMEIkQ5yijoh8CYMRIiIikhSDESIiIpIUgxFyCNemISIid2EwQiRD7G5MRL6EwQgRERFJisEIERERSYrBCBEREUmKwQgRERFJyulgJC0tDZMmTUJ0dDRUKhU2b95sM/0333yD8ePHo1OnTggLC8OIESOwbdu2luaXiIiIZMbpYKS6uhqDBg3Ce++951D6tLQ0jB8/Hlu3bkVmZibGjh2LSZMmISsry+nMEhERkfwEOHtAYmIiEhMTHU6/atUqk79fe+01fPfdd/jhhx8wePBgZ09PRA7gUkJE5EucDkZaS6/Xo7KyEhEREVbTaLVaaLVaw98VFRWeyBoRERFJwOMdWN966y1UV1dj8uTJVtMkJycjPDzc8IiJifFgDomIiMiTPBqMbNiwAUuXLsXGjRvRuXNnq+mSkpKg0WgMj/z8fA/mkoiIiDzJY800GzduxMyZM7Fp0ybcc889NtOq1Wqo1WoP5YyIiIik5JGakQ0bNuCJJ57AF198gYkTJ3rilESKxnUNiciXOF0zUlVVhTNnzhj+zs3NRXZ2NiIiItCjRw8kJSWhoKAAn332GYDGQGTatGl4++23cfvtt6O4uBgA0KZNG4SHh7uoGEREROSrnK4ZycjIwODBgw3DchcuXIjBgwfjlVdeAQAUFRUhLy/PkP7DDz9EQ0MDnnnmGXTt2tXwePbZZ11UBCJqjkN7iciXOF0zMmbMGAgbdcApKSkmf+/atcvZUxAREZGCcG0aIiIikhSDESIiIpIUgxEiIiKSFIMRIiIikhSDESIiIpIUgxEiGVKBY3uJyHcoPhjR6zlVJRERkZQUHYxszirAoGXbkX62TOqseD2GbOSNSipqcfFKjdTZIKJWUnQwsmBjNiq1DZiZkiF1VojISXq9wPDX/oc7/74T1doGqbNDRK2g6GCEiHyXzmgm6NJKrYQ5IaLWYjBCREREkmIwQkRERJJiMEIO4UBR36K0VXttLd5JRN6PwQgAwbEiJDNKuDcrLN4ikjUGI0RERCQpBiNEREQkKQYjROTzFNAqRSRrDEaIyCeplNZLl0jGGIyAi4oRERFJicEIOJrGEXyFfAsrDYjIlzAYISKfp4ShzERyxmCEiIiIJMVghIiIiCTFYISIZIDtNES+jMEIERERSYrBCNj5jYiISEoMRohkiCN7iciXMBghIp/nSO3m2d+q8PaO06isrXd/hojIKQFSZ8AbcIIo+/gSka+7+63dAIDiiqtIfvgWiXNDRMZYM0IkQ+wGZd3BC+VSZ4GImmEwAnZgJSIikhKDEXII4zXyZnx/Evk2BiNEpChcGJPI+zgdjKSlpWHSpEmIjo6GSqXC5s2b7R6ze/duxMfHIzg4GL1798YHH3zQkrwSkYPY4ZiIfInTwUh1dTUGDRqE9957z6H0ubm5mDBhAkaNGoWsrCz8+c9/xvz58/H11187nVkiIiKSH6eH9iYmJiIxMdHh9B988AF69OiBVatWAQAGDBiAjIwMvPnmm/jd737n7OmJiMywEzqRb3N7n5H9+/cjISHBZNu9996LjIwM1NdbnnxIq9WioqLC5OFO/B4jUg4GLkTex+3BSHFxMaKioky2RUVFoaGhAWVlZRaPSU5ORnh4uOERExPj7mwSERGRRDwymkbVbIpTce2nSfPtTZKSkqDRaAyP/Px89+bPrc9ORO4gWMVBJBtunw6+S5cuKC4uNtlWWlqKgIAAdOzY0eIxarUaarXa3VkjIiIiL+D2mpERI0YgNTXVZNv27dsxdOhQBAYGuvv0RMrE6j4i8iFOByNVVVXIzs5GdnY2gMahu9nZ2cjLywPQ2MQybdo0Q/rZs2fjwoULWLhwIY4fP45169Zh7dq1WLRokWtKQERERD7N6WaajIwMjB071vD3woULAQDTp09HSkoKioqKDIEJAMTGxmLr1q147rnn8P777yM6OhrvvPOOVw3rZcszkW/jrKpEvs3pYGTMmDE2O46lpKSYbRs9ejQOHjzo7KnIi7CvIBERuQvXpiEiIiJJMRghh1gZhU3eijVZVvGlIfI+DEaIyOexGZHItzEYIZIj1mQRkQ9hMEJERESScvsMrEREUkr+73Fcrqoz/M1p5Im8D4MRIvJ5tuKLD3ef81xGiKhF2ExDREREkmIwQkRERJJiMAJw4gEiBeHHncj7MBghkiGVwsb2cm0aIt/GYIQcwgEIJBfKCtOIfAODESIiIpIUgxEiIiKSFIMRgPW2RD7OmWZEtjgSeR8GIwC/nYiIiCTEYITIiBACa/fmYt+ZMqmzQkSkGJwOnhyiUkhT1t4zZfjrf3IAAOdXTJQ4N64hhIBKKReQiHwSa0aIjFy8clXqLJC7sVmWyOswGCEiIiJJMRghIiIiSTEYAaeSJvJ1nCGYyLcxGCEiRWHcQuR9GIwA8ONIA7v4y5OIiNyFwQiAAD8GIyRfcg0kW1osftqJvI+ig5HbenUAAIzt31ninBC5Fiv7iMiXKDoYiesWDgDo2bGtxDkhIk+RaUURkU9TdDDSRK7V2ERERL6AwQgRERFJStHBiIpd2YhkwdpcQYLVnkQ+QdHBCFFzDE/ljwEKkfdhMEJkRI63KTmWiYjkhcEI+GVN8sMaHiLyJQxGiMjnebrl5dfzl3G0QOPZkxLJWIuCkdWrVyM2NhbBwcGIj4/Hnj17bKZfv349Bg0ahLZt26Jr166YMWMGLl261KIMkzQ4iZZvYW2f+1yq0uIPH+zH/e/ulTorRLLhdDCyceNGLFiwAIsXL0ZWVhZGjRqFxMRE5OXlWUy/d+9eTJs2DTNnzsSxY8ewadMm/Prrr5g1a1arM99avME6jn3+SC5a+1YuqdC6JB9EdJ3TwcjKlSsxc+ZMzJo1CwMGDMCqVasQExODNWvWWEx/4MAB9OrVC/Pnz0dsbCzuvPNOPP3008jIyGh15olcjfGpb/JkrMwfMUSu51QwUldXh8zMTCQkJJhsT0hIQHp6usVjRo4ciYsXL2Lr1q0QQqCkpARfffUVJk6caPU8Wq0WFRUVJg8iIm9gHIxwmDCRazgVjJSVlUGn0yEqKspke1RUFIqLiy0eM3LkSKxfvx5TpkxBUFAQunTpgvbt2+Pdd9+1ep7k5GSEh4cbHjExMc5k02n8PqEmcnwrKOGGeSi/3OG0ra3Y4GSJRK7Xog6sqmb1lEIIs21NcnJyMH/+fLzyyivIzMzEjz/+iNzcXMyePdvq8yclJUGj0Rge+fn5LckmkWIp7Xb5c67jHeJdGZopIM4j8ogAZxJHRkbC39/frBaktLTUrLakSXJyMu644w688MILAIBbbrkFISEhGDVqFJYvX46uXbuaHaNWq6FWq53JWoso7QubSK6sBQXuDhYYixC5hlM1I0FBQYiPj0dqaqrJ9tTUVIwcOdLiMTU1NfDzMz2Nv78/AGVUHxOR+3nyq4R9Rohcz+lmmoULF+Ljjz/GunXrcPz4cTz33HPIy8szNLskJSVh2rRphvSTJk3CN998gzVr1uDcuXPYt28f5s+fj2HDhiE6Otp1JSFyAdaW+SZrC+W5g/F7hKEIkWs41UwDAFOmTMGlS5fw6quvoqioCHFxcdi6dSt69uwJACgqKjKZc+SJJ55AZWUl3nvvPTz//PNo3749xo0bh7///e+uKwURkYNaW5lhWjPSuuciokZOByMAMGfOHMyZM8fivpSUFLNt8+bNw7x581pyKo/w5K8qInI9zwYF16MRfncQuQbXpiEyIsdbixzL1JxUZWTNCJFrKDoY4UyKjuN3rm+xNtRerqTqwEpErqHoYISIlKe1TSsmHVgZpRO5BIMRIiP80eurGBUQ+TIGIwC/x4h8nFQ1FOzASuQaDEbIIawxIGpk3B+HzTRErqHoYERpnfxIOTgzqHWtXeiOk54RuZ6igxEiJVBCXKK3UkhLW1vdgZXTwRO5HIMRIhlSWq2fzpNDe00mPSMiV2AwQkQ+ybhSorSiVvI8EFHLMRgBf90Q+boTxZUeO5eKnUaIXI7BCBEpiitrMzi0l8g1FB2MKKtVnYhcgav2ErmeooMRchy/c4mIyF0CpM4AEbmXUpoSer20BS/ceyOiwoIRFabGjVGhePLTX83SXbxyFVuPFCEsOBChwQEIDQ5AWJvG/6sD/E3SniiuQFZeObp3aIPbe3dEoL/p77dP9uWiQ0iQW8tF5Cmj+3VC707tJDm3ooOR49c6vWXnlUubESIXszeyt7ZehxX/PYFx/Tvjrn6dPJMpD3hj20mH0s1Zf9Dqvt6dQvDT82Nw8UoN7lu1x7C9Z8e2uO/mLjh8UWPY9s5PZ1qeWSIv886jgxmMSCHt1G8AgF/OX5Y4J0SetXZvLlLSzyMl/TzOr5godXZcalTfSJwsrkRppdZqmtt6dUBlbQMqrtajsrYBldoGw75zv1Wj10tbTNJ3aBuIC5dq8GHaOZPtkwZFuzbzRBLq1j5YsnMrOhiZcUcvfLLvPL9QSHHyL9dInQW3+OOYPnjxvv4oq9Ji6PIdFtM8P74f5t3d12SbTi9QUlGLkSt+snjM3hfHISX9vFnNy7uPDnZNxokUTtEdWDu0bWzrbadWdExGCiTXUSCBfo3tU5Ht1FbTXKmpN9vm76dCdPs2yE2egOSHB5rtD1EH4JmxN2DJpJvQJtDfbD8RtY6i78LXvre4voQDjhdVSJ0FciG5dmoN8Lf8+2r8TVFIzSkBANzVL9Lq8SqVCo8O64F26gDM25Bltn/GHbGYcUesazJLRAbKDkauRSM6vTy/mF3pNxvt7+R75Bp/B/hb7rn70bShOJRfjqOFGox2oMNu/y6hrs4aEdmg6GDE/9qQA51cv5nJaXJcX87S21uu7/hAP+stz4Ni2mNQTHuHnsdWMw8RuZ6i+4z4X6sZ0bNmhK6RS1xqL6aSa21goJWaEWeFtQk0/P+mrmEueU4isk7RwYifoWZE4owQuZGlAGv3tWHtcmOtz4izmn6oAMCtPdq75DmJyDpFByOsGSGlulqnkzoLbhHkomDEWFVtg/1ERNQqig5G2IGV5MpkMTcLPUTkO5rG9Z1+KmvNhwITkWspOxi59r2ll0tHATeKClNGhz75dGC9XhCLHVhl+pZvvnZMa3S8tubMnX3lM10+kbfiaBowGHFEp1BlBCNyqSQzrRlRDld1YAWALfNH4efcS5g4sKvLnpOILFN0MMJmGscpJV7LvHBF6iy4hPEt2dKkfnK9nK6sGekSHowHb+3msucjIusU3Uzjz9E0DlNKMKJt0EudBZdQGVWNWLx0Mr2erhpNQ0SepehPLkfTUHNKWRqgTiePoKs5VzbTEJHnKDoYYTON4/gK+RbTZhrJsuFxxs00js62SkTSU3QwwungqTmVTIbTmBRDQW/vAKPJygYzGCHyGS0KRlavXo3Y2FgEBwcjPj4ee/bssZleq9Vi8eLF6NmzJ9RqNfr06YN169a1KMOuxFV7HaeU10gu5VQZD+1VUDRiXDPCGk8i3+H0aJqNGzdiwYIFWL16Ne644w58+OGHSExMRE5ODnr06GHxmMmTJ6OkpARr167FDTfcgNLSUjQ0SD+rYVMzDb+zSG5MhvYq6P1tHIxwyD6R73A6GFm5ciVmzpyJWbNmAQBWrVqFbdu2Yc2aNUhOTjZL/+OPP2L37t04d+4cIiIiAAC9evVqXa5dxLA2DaMRkjElvbuNZ2B9alRvrP85D5OHdpcwR0TkCKeaaerq6pCZmYmEhAST7QkJCUhPT7d4zPfff4+hQ4fi9ddfR7du3dCvXz8sWrQIV69ebXmuXYTNNI5TykukkGLKVqDf9a+0XpEhOLn8Prz++0ES5oiIHOFUzUhZWRl0Oh2ioqJMtkdFRaG4uNjiMefOncPevXsRHByMb7/9FmVlZZgzZw4uX75std+IVquFVqs1/F1RUeFMNh3GZhpqLtBPfh1YlRRs+zX7eaUO8JcmI0TklBZ1YG0+4kAIYXUUgl6vh0qlwvr16zFs2DBMmDABK1euREpKitXakeTkZISHhxseMTExLcmmXWymoeZGyXAdEiW9uwOaRyNE5BOc+uRGRkbC39/frBaktLTUrLakSdeuXdGtWzeEh4cbtg0YMABCCFy8eNHiMUlJSdBoNIZHfn6+M9l0GNemcZxSRmS4Y9VXqcn17W3pPclYhMg3OfXRDQoKQnx8PFJTU022p6amYuTIkRaPueOOO1BYWIiqqirDtlOnTsHPzw/du1vuWKZWqxEWFmbycAeu2ktKoJRAEmDNCJGvcvqTu3DhQnz88cdYt24djh8/jueeew55eXmYPXs2gMZajWnTphnST506FR07dsSMGTOQk5ODtLQ0vPDCC3jyySfRpk0b15WkBdhnxHGM13yYgq5diJp9RIh8kdNDe6dMmYJLly7h1VdfRVFREeLi4rB161b07NkTAFBUVIS8vDxD+nbt2iE1NRXz5s3D0KFD0bFjR0yePBnLly93XSlaqKnPCNemsY+vkO9SyrXbsfAudlgl8lFOByMAMGfOHMyZM8fivpSUFLNt/fv3N2va8QZN8yOxmYaalFZo7Scir9Mvqh1u6BwqdTaIqIUU3cCqUrGZxlFKGR56pabO8H+5lFkmxbBJCWUkkjNFByMc2ku2yOUGp6QOrETkmxQdjDQN7ZXLL2B3UsorNLDb9SHocimzEt7eXdtL2xmeiFpH0cFI0zxtOiV8W7eWQl4if6MZWOUSpMqjFLYte+BmqbNARK2g6GDEn0N7qRnjmYTl8raQS1BlS2S7IKmzQEStoOhghEN7HcdXiIiI3EXRwQiH9jpOCb+uAcB4Mni5FNleOX6r5HBmIpKWooMRDu0lW5QyCuVqnU7qLBCRwik6GGEzjeOU8goZLz6tlJqRNkGctZSIpKXoYISr9lJzKvkt2mu3hkeOZSYi36LoYIRDe6k5FYyH9kqYEReyVw4G40QkNUUHIxza6zjF3K+Mm2l8uHHK+HrZK4Ve79asEBHZpehghH1GqDk5jqaxhzUjRCQ1ZQcjHNrrMF+uJXCGEic94/ufiKSm7GDEaGivUubRIMfJ5T3BZhoi8nYMRq6RyX3HbZT4+silyOzASkTeTtHBiL9RMMIvZNuU8vLIsc/IxSs1NvdzNBkRSU3RwYjKqPT8QrZNp5BOvnKcc2P/2Us29//veImHckJEZJmigxF/NtM4rLiiFg06+XcuUJmO7ZUFe7V+NZwOnogkpuhgxLjPiFJ++bdGQflVqbPgdiqZzDNiLDQ40Ob+UX07eSgnRESWKTsYMSo9+4wQIM8+I6t2nLKTQiYFJSKfpexgxLgDq/xbIFpNLjdnR8mluPYq/VgpSERSYzByDWtGqDm5zDNiD5soiUhqCg9Grv+fwYh9iniF5Nd/1a68y7aH/hIRuZuigxGVSsWVe8mEHFfttefNbSelzgIRKZyigxHg+vBepdx4WkMpzRZN5DKaZuItXW3ub6cO8FBOiIgsU3ww4netraaB7ebUnEzeEp1D1Tb3P3FHL89kxMUUFhsTyZrig5GAa8GITsdvNnuU9grJpbyamnqb+wP9ff9rQCXHqXOJFMT3v4VaKcBQM8KxvSSfphlj5VdtByM/n7M9XTwRkbsxGLn2q5DNNNScXJoBrtTU2dx/8Yr8Z9YlIu/GYKSpZoTNNHZVaxukzoJHyaWWxF4zTWxkiIdyQkRkGYMRNtM47IH39kmdBY+SS82IvWaaTZkXPZQTIiLLFB+M+Ps3BiPpdpZZJ+WRSSyC8po66NkMSUReTPHByOWqxvb0Ff89IXFOyNvIZV4VvQCq6mw3sdXW6zyUGyIicy0KRlavXo3Y2FgEBwcjPj4ee/bscei4ffv2ISAgALfeemtLTusW1XX8EibLZBKLALDfb+RMaZWHckJEZM7pYGTjxo1YsGABFi9ejKysLIwaNQqJiYnIy8uzeZxGo8G0adNw9913tzizRG4nowDE2KVq2yNqThZXeignRETmnA5GVq5ciZkzZ2LWrFkYMGAAVq1ahZiYGKxZs8bmcU8//TSmTp2KESNGtDizRJ4kp5qRonLbw3ebhvceLdBgRPL/8G0WO7USkec4FYzU1dUhMzMTCQkJJtsTEhKQnp5u9bhPPvkEZ8+exZIlSxw6j1arRUVFhcmDvINc+lE44mK5fFazLdTU2tx/orjxMzb/yywUaWrx3MZDnsgWEREAJ4ORsrIy6HQ6REVFmWyPiopCcXGxxWNOnz6Nl156CevXr0dAgGMLciUnJyM8PNzwiImJcSabLVbXwOG99ihpUEbHENtruviSkgrbwch/jxZDpxc491u1h3JERHRdizqwNl8HQghhcW0InU6HqVOnYtmyZejXr5/Dz5+UlASNRmN45OfntySb5AZ6BdWMyGXSMwDYfqwYKftybdZsaRvYmZuIpOHU2uGRkZHw9/c3qwUpLS01qy0BgMrKSmRkZCArKwtz584FAOj1egghEBAQgO3bt2PcuHFmx6nVaqjVnv9VqqQbbUvp9AKB/lLnwjN0MqoGOn+pBkt/yEHHdmpMGhRtMY2cyktEvsWpmpGgoCDEx8cjNTXVZHtqaipGjhxplj4sLAxHjhxBdna24TF79mzceOONyM7OxvDhw1uXexcbtGw7Pj9wQepseDUlBWxyLOqRAo3VfTUc5k5EEnGqZgQAFi5ciMcffxxDhw7FiBEj8M9//hN5eXmYPXs2gMYmloKCAnz22Wfw8/NDXFycyfGdO3dGcHCw2XZvoG3Q4y+bj+L/3d5T6qx4Lbn/ejYunRzL+s+0c/jzhAEm2yJCgnC5ug6XqmwP/yUicheng5EpU6bg0qVLePXVV1FUVIS4uDhs3boVPXs23sCLiorszjniTfz9VLK86biLkpbw0flw1UhT1ju0DcQVOxOedWqnxuXqOly8Ynn00L9/zcc/dpzCJzNuQ/8uYa7OKhFRyzqwzpkzB+fPn4dWq0VmZibuuusuw76UlBTs2rXL6rFLly5FdnZ2S07rFkH+ip8R3ylKWlBQDsOYgwP90b5toM00MRFtAQD5VyzPRfKnrw+jSFOLBV9muzp7REQAuDYNggIU/xI4xZdrC5ylk0nc1TnUdmfwqLDG/X/9T47NdJftzOJKRNRSir8TBwcq/iVwioIqRmTTfHeqxPa6M7GRIQ49jzxeDSLyRrwTk1PYTCM/N3RuZ3F782BMIS8HEUlA8cFISYXW4bQNOj1e+vowNmcVuDFH3k1BsYhimqRujg63uP1qvelQX6UEZ0TkeYoPRpzxbVYBvvw1Hws2ZkudFcnI/QZtXDy5NNO8P3WIzf2drPQpMasZufbv0u+PYfa/MhmcEJHLKD4YWTje8Wnq2YFPPjdoR8jlXtvBzmgaa4o0pqNrmoKPlPTz+PFYMY4VSreAZYNcehcTEQAGI3hqVG+zbS9vPmoxrYXldxRHSeuXyCXwqtQ2tOi47Lxyk7+bvxpSvT47T5ai31/+i00ZXLOKSC4UH4y0CTJfaOVfVqaEV0F50UjPjm1N/p74zl6JcuJ5cpn6/rZeEWbbmoa0f/D/4gEAuxaNsfs8zV+OkyWVrc5bSzz1aQb0Anj5u2OSnJ+IXE/xwQjZFhbcsip+OZBLMGKpmSa8TeO2HtcmPOsVGYKfnh+NrJfHG9JorprO3Nr89ThbanvIsLv4sYqSSHacng5eyfgdqCxy6ZagcvCN27uT6RDfzmGmHVtr63WmTTNSfR74OSSSHdaMEFkhl5oRAAgLbvzd0dZCs6Q1e09fMvm7Xicw6d3rzXRSNVsyFiGSHwYjREaEUTdNOQUjTX1Eauoc74B8rFBjti2n6PoImmKN5bVs3I01lETyw2DECY5Wd5M81OvkE4w09RFxxLIHbgYAtG8biCs2hrNvzi5sdb5awlKfEX4yiXwbgxEnGH/h7TpZKlk+PEkoeEUSOcxl0fSeXf7QQIePub13RwDAgXOXMfivqVbT+fuxmYaIXIPBiBOMf5A98cmv0mWEPKJOBsFIk1u6X5/y/c1tJw3DdC1V9vWLaocABwKN6PbBrsqeU1hDSSQ/DEZk5Jfcy3h87c84+5s0Qy7lpq7Bd4OR5jVaIerrA+fe23kGZVXW12RSqVS4Z0CU2/LWWgxFiOSHwYgTvP1LcPKH+7HndBlm/ytT6qzIgpxqRgDAmVaVtx+91W35aDUL5WBlCZFvYzAC4PXf3SJ1FlyqSFMrdRZkob5BXv1l2rcNcjitOsAfP8y902YaqVZw5qRnRPLDYATA7+O7O5TuRLE00187S26/6KVSp5PXOjzOLvQ40KifiSUF5RzaS0SuwWAEgJ+D9de+Mu+Eu/s67Dwh35FExpdYTkN7AeeG9zbZ/txdDqdt0OnxZMqvWLXjlNPncQZjESL5YTBiRWmleVNHcKDjs1fK2YwUZYwk8uUOrJb8Z57tZhdL+kWF4rMnhzmU9n8nSvHTiVKs2nHa6fM4g6NpiOSHwYgVq3eeNdu2/ViJBDkhqcituSsmoq39RBbc1a8TBsW0t5tO66HgzVIoosQVtYnkhMGIFdXaBrNtxRXsGKoktfXy6jPSGp/OuM3m/s1ZBZi/IcsjeWHNCJH8MBixwlO/8sh7XXViHRdf8ZeJA1p0XPu2QXjrD4Os7l+wMbuFOXKeIxOyEZFvYTBixfeHpFl3g7xHtQyDkVmjerf42PviuphtKyy/6vFp86Wahp6I3CfAfhIiZbpaZ95UJwc9O7bFhUs1AExHD9ljPItrk5ErfsKovpFm23V64bagwc/CTyi23BD5NtaMEBkxvjdXaeVXMwIAPz0/xvB/zdV6p46N79nBbNue02Vm24Qbh8EHWIpGiMin8VN9zb03e+9aHCSNCidv1L7C30+FUX0j0a19Gwzu0d6pY9fPGu5QOr0bp2hhKw2R/DAYueYNC53zThZXoqJWnjcksq95MKJ35x3Wwz57chh2vzDG6blzggPtTxMPuHeCQNaMEMkPP9XXhAWbz05576o03PX6Tgly4/2EENiRU4L8yzVSZ8VtKrUNqLo2xHtHTgkGLduO7ceKJc6Va6hUKgT4t+zjP7B7OIICbB/rzmHRjs6YTES+g8GIHeU1rBmxZNfJ3zDrswyMknmw9sfPG1dAnvVZBiq1Dfg/H1sR2V1zcjx0a7TN/ceL3LeOU5A/gxEiuWEw4gBrnfHc2UnPW1gr4q/nL3s2IxKx1DnTF7j7rXlrjHlHVmOZFy7jTGkVcgorUOLiyQK5LAOR/DAYMRJqYegiAMQmbcVvlVpMH9HTZLvOTh8CvV7gaIEG9TKbVlxplBB0OuuhwbZrRt7cfgr3rNyNCe/swfDX/ufSc7cJYjBCJDcMRoxs+L/bre7701eHEBGiNtmms3OTeuen07j/3b149J8HXJI/byLXeR0sBR7zPDTNuS9pGxSA/l1CJTl3cACDESK5aVEwsnr1asTGxiI4OBjx8fHYs2eP1bTffPMNxo8fj06dOiEsLAwjRozAtm3bWpxhd4rrFm51X97lGgiY3qj0dio8mlYvzbhwpdV5k0rTvVnJU3D/53CR1FnwShv/b4RZbaE1ZVVaVGsbXDLFPmtGiOTH6WBk48aNWLBgARYvXoysrCyMGjUKiYmJyMvLs5g+LS0N48ePx9atW5GZmYmxY8di0qRJyMryrV+bHdoGmbXDN9iLRlrg1/OX8db2ky5Zvr60ohaPr/0Z21wwAuTj6UNN/lbyKqnPrD/IRfQAhLcNxLIH4xxKO3T5Dty8ZBsGvPIjLlVpW3VeS31G5FpTR6QUTgcjK1euxMyZMzFr1iwMGDAAq1atQkxMDNasWWMx/apVq/CnP/0Jt912G/r27YvXXnsNffv2xQ8//NDqzLvDl1aaakb17YTmFfj2YpHYyBCnz/+HD/bj3Z/O4LP9550+trlX/5ODPafL8HQrRoA0ldmv2bd9tdFU6a7uoOgNwtuYD/VusuVIET4/cMGDufEd42+yP3nglFY2WwYHsnWZSG6c+lTX1dUhMzMTCQkJJtsTEhKQnp7u0HPo9XpUVlYiIiLCahqtVouKigqTh6fc3ruj5Tw16MyGKPxWZfsm3Jofa2d/q27F0Y0uVdW1+jmMTRzY1fD/IKM5Kv6Zds6l5/EGke2CbO6X6+ysLXH6b4mG/380baiNlI3OlFa16nwcTUMkP04FI2VlZdDpdIiKMv31ExUVheJix5oC3nrrLVRXV2Py5MlW0yQnJyM8PNzwiImJcSabblFbr8d/jpj2HXhr+ymbx7Sm6tgVK6G6supapQKWPHATgMbpuI0XQXNFk5K3sdcvwV3zd/iiQH8/nF8xEedXTAQA/Gee/Rlam9PrBSa9uxd/2XzEblq+8kTy06L6zuZfxEIIh76cN2zYgKVLl2Ljxo3o3Lmz1XRJSUnQaDSGR35+fkuy6VK1DTqca1Zb0b6t7V/Prblhbcq82OJjr5+/1U9hMrpEfW0Ug14A0e3bGLbLMRixp3mzFV0X1y0c516bgEeH9bCa5mqdDnO/OIj/HinC8aIKfHeoAEcKNPj8QF6LAnFOEU/k2yxPrGFFZGQk/P39zWpBSktLzWpLmtu4cSNmzpyJTZs24Z577rGZVq1WQ61W20zjadp68y9Ie/NP2BuAUllbj1AL09C7iqs7maqNpgB/+3+nDf+3N8TZlzhakhbOpK4Yfn4qJD88EFOH9cCk9/aa7R/wyo8ALI9U0glh84vJ0jXyV/BoLyI5cOorNSgoCPHx8UhNTTXZnpqaipEjR1o9bsOGDXjiiSfwxRdfYOLEiS3LqQdZmuq6tsF89ES1nWGKtoKBnSdLMXDpdiT/97jzGXSATi9c20wDlUkw8lvl9RERt/WyPRunL7IXyLGZxjEDu4ejf5dQdApV40E7U8g3aW2fEiLyPU7/vlu4cCE+/vhjrFu3DsePH8dzzz2HvLw8zJ49G0BjE8u0adMM6Tds2IBp06bhrbfewu23347i4mIUFxdDo9G4rhQuZqm/gNbCUM5qbYPZNkf99T85AIAPd7un82e9Tu/yG6a155NrM8325+6yuq+slcNTleTHBXfh18X34O1HBjuUfuI7e/HjUceHo0+8pav9RETk1ZwORqZMmYJVq1bh1Vdfxa233oq0tDRs3boVPXs2Tn5UVFRkMufIhx9+iIaGBjzzzDPo2rWr4fHss8+6rhQutuEX8z4qNRZqQez9grMVC/g7ECi0ZhryOp3eYx39rsp0zo1+UdZnGP1k33ks+e6oSzoaK8nKyYMcSjf7c/vD0Uf07oh7b47C0kk3tzZbRCQxp/qMNJkzZw7mzJljcV9KSorJ37t27WrJKSTVNTwYRRrTYbu19TpMHtod/8643rF0XH/rnXAB250cHWnjfuC9fejRsS3eeWSwQ+mjwtQoqWj8xV7foLfbZ8UZtmKnq3XKvCF/uv8CBnQNwyM2OmqSqYeHdEeHtkGYkfKr3bRXquvg56cym/OlKUa/KToML99/kzuySUQexm54Fux+YazZtpo6HRqaLYxna/p4AAgMsP7yBjiwDPqRAg22HC5C2qnf7KYFTPs51On0CHRBL0tHKme+/NXy7LtykPEX252tv80qwG4Hrw81Gtu/M04uv89ugD34r6kYtGw7Xt58FH/ZfAQXLlUj/WyZ4f3GXjtE8sFgxIIgC0HEubJqfHOwwGTb1TrbfUaCbQQjV6rrjf5ve3KyKgf7phivnVPfIKB2w+RQn8y4zWxb81okOYlsp8Zjw63XfPycexnT1/3CGVmdpA7wx9nXJuBfM4fZTfuvAxfw+YE8jH5jF6Z+9DPKazjhHJHcMBhxkKVOmva+FG3NFFlQftXw/9e3nbT5PIVGaW0xrsWo0+lMZkltqaYAp+lX6NgbzZumQoNb1NrnnSzUBP3VgfVX/rL5qBsyI3+j+nZCbvIEdkIlUjgGI1acXzERG56yvE5Nk2+yCmzuN66+b9DpIYTAR2nn8NOJEvSLamfYt+EX280cyf894UCOTe+jdQ0Cag+t4VFZ2wCNC3+t5pZV48ejRa3qwNtShuDLqA3Az0+FEVaWCfBWvjTzi0qlwvtTh+D8iono3YL1nIjI9zEYsWFEn45If2mc1Zkkc8uqMXDpNly4ZH8dmZp6HbLzy/G3rcfxZEoGItu5flI305oRPYID3LOGx8NDuplte35Ttsuef+ybuzD784PYddLzfTGaXsPmw5gtNU81p9dbDwGOFmhQWinf5ixX+WnRGMy6M9ahtFn55e7NDBF5DIMRO6Lbt8EzY/tY3V9Z24DRb+zC8v/kYPhrO/D42p/x74x83Hxthskmh/M1qKi93vejbZBzTRtFGkeaaq7fDLX1OrQJun55W1rLYDjM6N68cvKtZul2HC9t0fPbkpV3xeXPaU9TPNG8c6Qji7MZN70dzLuC4mt9aY4XVeD+d/di2N/+56psytpf7r/JZPE9azIveP79QUTuwWDEAd07tMXORWMMf59cfp/ZbJIf781FSYUWe06X4U9fHTabnbVep0c7tb/J3844ctG5SeIqaxvQxugGqnXxxGTzx91gtk0IYbdctfU6PP2vDHzxs/0ROBoJVsZtCtosDfQwblqz5fDFcjy8Oh23JzcGH/vPXnJZ/pSiafG9P8R3lzorROQBDEYcFBsZYliZVB3gjzf/MMjiqBtrnt90yLDQHOD8RGGO1GsYV36UX603+TVvadK21liYcCNykyeYbItN2oq+i/+Lj/ecw/s7z+B8mXnz1easAmw7VoI/f2t/ddayKtujjNxBb6WZBgDuvKGTzWObXn/j2UOrtQ0uDwSV5I0/DMLnM4dLnQ0icjMGIy0U6O+HU8sTce61CXj9d7fYTX+5ug73v3t9wbBfci87dT5b/RGaGKdYtOmQyQ21pbOkXm+lMb85q1QqHFt2r9n25VuO441tJ5H49h6zfXVGNSf2Ou52bGd7VWT3MB09ZGz26N42j7x4pQaA6cKB1doG1BgNAddaWOOIbLuzbyRykyfg7UduNdn+xu/tf+6IyDcwGGklPz8VJt8WY6g1yXn1XsS2YkRA9w5tLG63tygfYN4vxPhve3OitFSIOsBqMHa1XofK2no888VBrNl1FgAQEXI9wEj65giSvjmC9LNlFo/XORCAuVrTS2Zp9tzOYcFmtUHGvjrYODvvIaOOlQ16YTKqqrSCa9q0hEqlwoO3dsNRo+B39I22a6qIyHfIaIII79A2KAA7F42BEAL5l68iRO2P+OU7HD7e2qyUp0sr7R5r69bt6mYaY5Nvi0FB+VW8/b/TZvsGLt0OANhyuAiTh3ZHWLDp1N4bfsnDhl/ycH6F+WrORwsr3JNhG/QWOuwas7X4YFPt1YFz12u9GnQCheXXR9EcvqhBTETbVudTqdqpA5D18njU1OvQOTRY6uwQkYuwZsRNVCoVenRsi47t1Pjf86Ptpm+6kVkb9HKhrMbuczQ/1nj6+vOX7B9v+TnN592w5Lnx/bD3RfNp9I0dulhutYPr6ZLGYMt4mPQhCYZuNp/kzZLc5An44xjzEVabswvxr/3nTbYdLdRgcI/2hr9rrzWXSTGHilx0CAlCt/aWaxCJyDcxGPGAPp3a4dxr1qv3AeCRjw4g71KNyZTuxoynhD9yUYPtx4qx9PtjKCy/irV7c5H0zWGzG9yJous1C5ZmkHW17h3a2iznkykZ+P5QocV94/+Rhiptg8Pr8LiLrWaaJiqVCi/e19/irKEvf3fM5O/PD1xAak6J4e81u8+i10tbEJu0FaUVjTUmV91Ya0VE5AvYTOMhfn4qHHx5PN7afhJ33hCJP64/aLL/l9zLuOuNnVaP33umDGVVWrz6Q47JDT0r7woOWRn2uzn7erqCK1chhLDZzGCJs7/f/fxUOL9iIp7+Vwa2HSsx2/9dtuVgBADilmxz8myup3ewJggA3p86BG/+Xofzl6otdtYFgPRmw3rPlFYZ/p+Sfh7V2gZ8uv8Cvp97B27p3r7F+SYi8mWsGfGgiJAg/O3/G4jEgV2xa9EYrHtiqFPHD12+w6xmwVIgMsdCE8I/dpzCgFd+RP7lGgghUFlbjwYLTSYniiuQcd58pI+zK6R++PhQnFpuf+IqW/p3CYVeL/B15kW8Y9QfpXkN0AubDuHB9/c5PXeLLY7GbG2C/DGga5jZSA9H5BRV4NP9jQvsPfDePnyXXYDyGs8PZyYikhprRiTSKzIEvSJDsPfFsbjz79ZrRFriwVu7YfW10SvGauv1GPX69XPd0j0c38+90yTNfasaf+H/svjuVncQDArwQ27yBHz5az6SvrE/r0hzJ4or0fvPWw1/19brcKWmHqk5xZg9ug8OXdRg+UNx2JTZOIol/ewljO7n3AgLvV5gx/ES3NK9PbqEBzvUTGPJg7d2w/23RKOPUX7taT7d/bNfZgNoHLL6uyHd4WelMzMRkdywZkRi3TvYH1nx7ZyRTj2nOsAP9wwwX123ucMXNej10hZMW/eL2cJ0+ZevTW3eyn6WKpUKjw7rgcy/3GOyffxNUTi/YiJSn7vL4edavessNvySh7KqOizfchw/HCrEyu3XVzw27nuR9M1h9HppC/6ResqsBii3rBqv/3gCl6q0+O5QAf7vX5m461qQpm9Fx1L/a01UTY+WeuGrw3ju39kAGmdvHf7aDpN+J0REcsNgxAuctdO59aboMOQmT8Ar99/k0POpVI3NJE1evK+/zfRpp37D7M8P4uE16YZtf9uSg4/3nMO5a7OoOtvXpLmO7dSGm/TRZffio2mN+esbFYrzKybi0WExLXrepmYOANhxvATnfqvCok2HsOGXfADA2/87jS+aTa72uzXpWL3rLJ7fdAh7TjfOcdI0GVtLa0YsOb9iIp4a5diib819l12Iq3U6PPrRAZRUaPHUZxk4c214d9qp3/Da1uMubZYiIpKSSvjAGMOKigqEh4dDo9EgLCxM6uy4hV4vTJokfvnz3Rj2WuPaJs1/ZWsbdHh581H8O+OixedKe2EsenRsiwadHmd+q0L/Lo2v2ZvbTuK9nWdalL9/Pz0Cw2IjWnSso6q0Dfj8wAWs+O8J/GXiAOw5XWYyYVhr9Ihoi9t7R+D13w9Cr5e2GLZPHtrd8DqeXzERmzLy8cJXhzHmxk5ImTHMJedukn+5Bq/+JweHL5Zj/E1R+PyA/fV5bHlqVCwWT7QcoGbnl+Oh9/ehW/s22PfSuFadh4iopRy9f7PPiJdoGoVSpLmKDm2DEBzob7WqXx3gj9d/Pwiv/34Qvjl4EQv/fajZczX+G+DvZwhEAGDRvTfi+YR+OFVShXtXpTmVPxdUFNjVTh2A2aP7YPboxg64s0Y1Tr9+qqQSCf9wLr/N5V2uQd7lGjw0uJvJ9gB/08pBO3OetUpMRFtDjRAA3N0/CjNSfm3x8320Jxfz7u6LYk0tekS0RXlNPbqEB6Nep7c6qy0RkTdiMOJluoY7N5nTw0O6I65buMnNOqxNoNX0KpUKN3ZpbBoRQmDRpsP4+qDlGhZjwUaL/Hlav6jr+f00/TyW/pDT4uea+tHPJn9fqa4z+b/22qRkrmimsWds/844v2IiKmrrMe7N3Sircn6q+FuuzXDb5IFB0SYjrgL92QmWiLwfm2lk5LvsAoS1CcTYG+13Xm1uxie/YOdJ600i25+7C/2iQluTPZfT6QW2Hys2m7PFFe4Z0BkfT7/N5c9ri7ZBh8LyWqzaccrmfCzOCAsOwOGl5osZEhF5gqP3bwYjZKDTC7z49WF8lWleU/Ll/92O23t3lCBXjtPpBXIKKzDni8zro4FaqHdkCH5aNMY1GWshIQSW/ZCDnMIK/GJh7hdHtWZkDxFRazAYoVY5lF+OB9/fZ/j7zN8SzfpXeLvMC5ex/+wlVNfpDKsGO8Mbb+Ip+3KdbqbyxnIQkTIwGKFWq9fpodMLBPn7yWICLr1eIP9KDUa/scuh9N5+Ez/7WxV+PFqMb7MKcLm6DperLc/e6u3lICL5YjBCZEVdgx6Xq+vg5wfM+yILP+dabgLxxZu4Ti9wprQKRZqrOF5Uidmje7d6jhgiopZiMELkpB05JXh+0yFortbj0JIEhNsYlURERPYxGCEiIiJJOXr/9q0eiURERCQ7DEaIiIhIUgxGiIiISFIMRoiIiEhSDEaIiIhIUi0KRlavXo3Y2FgEBwcjPj4ee/bssZl+9+7diI+PR3BwMHr37o0PPvigRZklIiIi+XE6GNm4cSMWLFiAxYsXIysrC6NGjUJiYiLy8vIsps/NzcWECRMwatQoZGVl4c9//jPmz5+Pr7/+utWZJyIiIt/n9Dwjw4cPx5AhQ7BmzRrDtgEDBuChhx5CcnKyWfoXX3wR33//PY4fP27YNnv2bBw6dAj79+936JycZ4SIiMj3uGWekbq6OmRmZiIhIcFke0JCAtLT0y0es3//frP09957LzIyMlBfX2/xGK1Wi4qKCpMHERERyZNTwUhZWRl0Oh2ioqJMtkdFRaG4uNjiMcXFxRbTNzQ0oKyszOIxycnJCA8PNzxiYmKcySYRERH5kBZ1YG2+8JYQwuZiXJbSW9reJCkpCRqNxvDIz89vSTaJiIjIBwQ4kzgyMhL+/v5mtSClpaVmtR9NunTpYjF9QEAAOnbsaPEYtVoNtVrtTNaIiIjIRzlVMxIUFIT4+HikpqaabE9NTcXIkSMtHjNixAiz9Nu3b8fQoUMRGMhVUYmIiJTOqZoRAFi4cCEef/xxDB06FCNGjMA///lP5OXlYfbs2QAam1gKCgrw2WefAWgcOfPee+9h4cKFeOqpp7B//36sXbsWGzZscPicTc067MhKRETkO5ru23YH7ooWeP/990XPnj1FUFCQGDJkiNi9e7dh3/Tp08Xo0aNN0u/atUsMHjxYBAUFiV69eok1a9Y4db78/HwBgA8++OCDDz748MFHfn6+zfu80/OMSEGv16OwsBChoaE2O8o6q6KiAjExMcjPz5ft/CVyLyPL5/vkXka5lw+QfxlZvpYTQqCyshLR0dHw87PeM8TpZhop+Pn5oXv37m57/rCwMFm+wYzJvYwsn++TexnlXj5A/mVk+VomPDzcbhoulEdERESSYjBCREREklJ0MKJWq7FkyRJZz2ki9zKyfL5P7mWUe/kA+ZeR5XM/n+jASkRERPKl6JoRIiIikh6DESIiIpIUgxEiIiKSFIMRIiIikpSig5HVq1cjNjYWwcHBiI+Px549e6TOkpnk5GTcdtttCA0NRefOnfHQQw/h5MmTJmmeeOIJqFQqk8ftt99ukkar1WLevHmIjIxESEgIHnjgAVy8eNEkzZUrV/D4448jPDwc4eHhePzxx1FeXu7W8i1dutQs7126dDHsF0Jg6dKliI6ORps2bTBmzBgcO3bMJ8rWpFevXmZlVKlUeOaZZwD43vVLS0vDpEmTEB0dDZVKhc2bN5vs9+Q1y8vLw6RJkxASEoLIyEjMnz8fdXV1bi1jfX09XnzxRQwcOBAhISGIjo7GtGnTUFhYaPIcY8aMMbuujzzyiFeU0d419OR7UoryWfo8qlQqvPHGG4Y03nz9HLkv+Nzn0KlFYmTkyy+/FIGBgeKjjz4SOTk54tlnnxUhISHiwoULUmfNxL333is++eQTcfToUZGdnS0mTpwoevToIaqqqgxppk+fLu677z5RVFRkeFy6dMnkeWbPni26desmUlNTxcGDB8XYsWPFoEGDRENDgyHNfffdJ+Li4kR6erpIT08XcXFx4v7773dr+ZYsWSJuvvlmk7yXlpYa9q9YsUKEhoaKr7/+Whw5ckRMmTJFdO3aVVRUVHh92ZqUlpaalC81NVUAEDt37hRC+N7127p1q1i8eLH4+uuvBQDx7bffmuz31DVraGgQcXFxYuzYseLgwYMiNTVVREdHi7lz57q1jOXl5eKee+4RGzduFCdOnBD79+8Xw4cPF/Hx8SbPMXr0aPHUU0+ZXNfy8nKTNFKV0d419NR7UqryGZerqKhIrFu3TqhUKnH27FlDGm++fo7cF3ztc6jYYGTYsGFi9uzZJtv69+8vXnrpJYly5JjS0lIBwGxxwgcffNDqMeXl5SIwMFB8+eWXhm0FBQXCz89P/Pjjj0IIIXJycgQAceDAAUOa/fv3CwDixIkTri/INUuWLBGDBg2yuE+v14suXbqIFStWGLbV1taK8PBw8cEHHwghvLts1jz77LOiT58+Qq/XCyF8+/o1/6L35DXbunWr8PPzEwUFBYY0GzZsEGq1Wmg0GreV0ZJffvlFADD5MTN69Gjx7LPPWj3GW8poLRjxxHtSqvI19+CDD4px48aZbPOV6yeE+X3BFz+HimymqaurQ2ZmJhISEky2JyQkID09XaJcOUaj0QAAIiIiTLbv2rULnTt3Rr9+/fDUU0+htLTUsC8zMxP19fUm5Y2OjkZcXJyhvPv370d4eDiGDx9uSHP77bcjPDzc7a/J6dOnER0djdjYWDzyyCM4d+4cACA3NxfFxcUm+Var1Rg9erQhT95etubq6urw+eef48knnzRZ9NGXr58xT16z/fv3Iy4uDtHR0YY09957L7RaLTIzM91azuY0Gg1UKhXat29vsn39+vWIjIzEzTffjEWLFqGystKwz9vL6In3pDdcw5KSEmzZsgUzZ8402+cr16/5fcEXP4c+sVCeq5WVlUGn0yEqKspke1RUFIqLiyXKlX1CCCxcuBB33nkn4uLiDNsTExPxhz/8AT179kRubi5efvlljBs3DpmZmVCr1SguLkZQUBA6dOhg8nzG5S0uLkbnzp3Nztm5c2e3vibDhw/HZ599hn79+qGkpATLly/HyJEjcezYMcN5LV2nCxcuGPLtrWWzZPPmzSgvL8cTTzxh2ObL1685T16z4uJis/N06NABQUFBHi1zbW0tXnrpJUydOtVkkbHHHnsMsbGx6NKlC44ePYqkpCQcOnQIqamphvx7axk99Z70hmv46aefIjQ0FA8//LDJdl+5fpbuC774OVRkMNLE+Jcp0HhRm2/zJnPnzsXhw4exd+9ek+1Tpkwx/D8uLg5Dhw5Fz549sWXLFrMPmLHm5bVUdne/JomJiYb/Dxw4ECNGjECfPn3w6aefGjrMteQ6eUPZLFm7di0SExNNfkX48vWzxlPXTOoy19fX45FHHoFer8fq1atN9j311FOG/8fFxaFv374YOnQoDh48iCFDhgDw3jJ68j0p9TVct24dHnvsMQQHB5ts95XrZ+2+YOnc3vw5VGQzTWRkJPz9/c2ittLSUrMIz1vMmzcP33//PXbu3Inu3bvbTNu1a1f07NkTp0+fBgB06dIFdXV1uHLlikk64/J26dIFJSUlZs/122+/efQ1CQkJwcCBA3H69GnDqBpb18mXynbhwgXs2LEDs2bNspnOl6+fJ69Zly5dzM5z5coV1NfXe6TM9fX1mDx5MnJzc5Gammp36fUhQ4YgMDDQ5Lp6exmbuOs9KXX59uzZg5MnT9r9TALeef2s3Rd88nPocO8SmRk2bJj44x//aLJtwIABXteBVa/Xi2eeeUZER0eLU6dOOXRMWVmZUKvV4tNPPxVCXO+otHHjRkOawsJCix2Vfv75Z0OaAwcOeLyTZ21trejWrZtYtmyZoRPW3//+d8N+rVZrsROWL5RtyZIlokuXLqK+vt5mOl+6frDSgdUT16yp41xhYaEhzZdffumRDqx1dXXioYceEjfffLPJ6C9bjhw5YtLJ0FvKaKl8zbnrPSl1+aZPn242Csoab7p+9u4Lvvg5VGww0jS0d+3atSInJ0csWLBAhISEiPPnz0udNRN//OMfRXh4uNi1a5fJELOamhohhBCVlZXi+eefF+np6SI3N1fs3LlTjBgxQnTr1s1sCFf37t3Fjh07xMGDB8W4ceMsDuG65ZZbxP79+8X+/fvFwIED3T789fnnnxe7du0S586dEwcOHBD333+/CA0NNVyHFStWiPDwcPHNN9+II0eOiEcffdTi8DRvLJsxnU4nevToIV588UWT7b54/SorK0VWVpbIysoSAMTKlStFVlaWYSSJp65Z05DCu+++Wxw8eFDs2LFDdO/e3SVDe22Vsb6+XjzwwAOie/fuIjs72+RzqdVqhRBCnDlzRixbtkz8+uuvIjc3V2zZskX0799fDB482CvKaKt8nnxPSlG+JhqNRrRt21asWbPG7Hhvv3727gtC+N7nULHBiBBCvP/++6Jnz54iKChIDBkyxGS4rLcAYPHxySefCCGEqKmpEQkJCaJTp04iMDBQ9OjRQ0yfPl3k5eWZPM/Vq1fF3LlzRUREhGjTpo24//77zdJcunRJPPbYYyI0NFSEhoaKxx57TFy5csWt5Wsa+x4YGCiio6PFww8/LI4dO2bYr9frDTUKarVa3HXXXeLIkSM+UTZj27ZtEwDEyZMnTbb74vXbuXOnxffk9OnThRCevWYXLlwQEydOFG3atBERERFi7ty5ora21q1lzM3Ntfq5bJo7Ji8vT9x1110iIiJCBAUFiT59+oj58+ebzdUhVRltlc/T70lPl6/Jhx9+KNq0aWM2d4gQ3n/97N0XhPC9z6HqWsGIiIiIJKHIDqxERETkPRiMEBERkaQYjBAREZGkGIwQERGRpBiMEBERkaQYjBAREZGkGIwQERGRpBiMEBERkaQYjBAREZGkGIwQERGRpBiMEBERkaQYjBAREZGk/n8/SdhXLMd+4gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.losshistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e027874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_19900\\2281346290.py:206: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_19900\\2281346290.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(Y, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_19900\\2281346290.py:218: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_19900\\2281346290.py:219: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(Y, requires_grad=True).float().to(device)\n"
     ]
    }
   ],
   "source": [
    "u00_1, v00_1, u00_2, v00_2 = model.predict1(test10_x,test10_t)\n",
    "u11_1, v11_1, u11_2, v11_2 = model.predict1(testb_x1,testb_t1)\n",
    "u22_1, v22_1, u22_2, v22_2 = model.predict1(testb_x2,testb_t2)\n",
    "a1,b1,c1,d1, ux11_1, vx11_1, ux11_2, vx11_2 = model.predict2(testb_x1,testb_t1)\n",
    "a1,b1,c1,d1, ux22_1, vx22_1, ux22_2, vx22_2 = model.predict2(testb_x2,testb_t2)\n",
    "\n",
    "f1, f2, f3, f4,a1,b1,c1,d1 = model.predict2(testu_x,testu_t)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f5c0224",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error_u0: 3.74156e-01, Error_ub: 0.00000e+00, Error_ubx: 0.00000e+00, Error_f: 2.74209e-06\n"
     ]
    }
   ],
   "source": [
    "error_u0= ((np.linalg.norm(test10_r - u00_1, 2))**2+(np.linalg.norm(test10_c - v00_1, 2))**2+(np.linalg.norm(test20_r - u00_2, 2))**2+(np.linalg.norm(test20_c - v00_2, 2))**2)/20\n",
    "error_ub= ((np.linalg.norm(u11_1 - u22_1, 2))**2+(np.linalg.norm(v11_1 - v22_1, 2))**2+(np.linalg.norm(u11_1 - u22_1, 2))**2+(np.linalg.norm(v11_1 - v22_1, 2))**2)/20\n",
    "error_ubx= (\n",
    "    (np.linalg.norm(ux11_1.cpu().detach().numpy() - ux22_1.cpu().detach().numpy(), 2))**2+\n",
    "    (np.linalg.norm(vx11_1.cpu().detach().numpy() - vx22_1.cpu().detach().numpy(), 2))**2+\n",
    "    (np.linalg.norm(ux11_2.cpu().detach().numpy() - ux22_2.cpu().detach().numpy(), 2))**2+\n",
    "    (np.linalg.norm(vx11_2.cpu().detach().numpy() - vx22_2.cpu().detach().numpy(), 2))**2)/20\n",
    "\n",
    "error_f= ((np.linalg.norm(f1, 2))**2+(np.linalg.norm(f2, 2))**2+(np.linalg.norm(f1, 2))**2+(np.linalg.norm(f2, 2))**2)/2000\n",
    "print('Error_u0: %.5e, Error_ub: %.5e, Error_ubx: %.5e, Error_f: %.5e' % (error_u0.item(), error_ub.item(), error_ubx.item(), error_f.item()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1854a589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f49206fcf84a9145e7e21228cbafa911d1ac18292303b01e865d8267a9c448f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
