{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20cdd684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import nn, optim \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import cycle\n",
    "from collections import Counter\n",
    "%matplotlib inline\n",
    "import random\n",
    "from torch.utils import data\n",
    "import os\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8e41b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dca358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x=pd.read_csv(\"data_x_new.csv\")\n",
    "data_t=pd.read_csv(\"data_t_new.csv\")\n",
    "data_xx=pd.read_csv(\"data_x_x.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "969f73bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "h10_x=data_x.iloc[:, [0]]#初值x,t\n",
    "h10_t=data_x.iloc[:, [1]]\n",
    "h10_R=data_x.iloc[:,[2]]#初值h实部\n",
    "h10_C=data_x.iloc[:,[3]]#初值h虚部\n",
    "hb_x1=data_t.iloc[:,[1]]#边值-5，t\n",
    "hb_t1=data_t.iloc[:,[0]]\n",
    "hb_x2=data_t.iloc[:,[2]]#边值5，t\n",
    "hb_t2=data_t.iloc[:,[0]]\n",
    "\n",
    "h20_x=data_x.iloc[:, [0]]#初值x,t\n",
    "h20_t=data_x.iloc[:, [1]]\n",
    "h20_R=data_x.iloc[:,[4]]#初值h实部\n",
    "h20_C=data_x.iloc[:,[5]]#初值h虚部\n",
    "\n",
    "h30_x=data_xx.iloc[:, [0]]\n",
    "h30_t=data_xx.iloc[:, [1]]\n",
    "h30_r1=data_xx.iloc[:, [2]]\n",
    "h30_c1=data_xx.iloc[:, [3]]\n",
    "h30_r2=data_xx.iloc[:, [4]]\n",
    "h30_c2=data_xx.iloc[:, [5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76bd3759",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_x['x']\n",
    "t = data_t['t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b2ca994",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, T = np.meshgrid(x,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc71aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf= np.hstack((X.flatten()[:,None], T.flatten()[:,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "950258e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_x=hf[:,[0]]\n",
    "hf_t=hf[:,[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78ff78e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train10_x,test10_x,train10_t,test10_t,train10_r,test10_r,train10_c,test10_c,trainb_x1,testb_x1,trainb_t1,testb_t1,trainb_x2,testb_x2,trainb_t2,testb_t2,train20_r,test20_r,train20_c,test20_c = train_test_split(h10_x,h10_t,h10_R,h10_C,hb_x1,hb_t1,hb_x2,hb_t2,h20_R,h20_C,test_size=0.2)\n",
    "\n",
    "train30_x,test30_x,train30_t,test30_t,train30_r1,test30_r1,train30_c1,test30_c1,train30_r2,test30_r2,train30_c2,test30_c2=train_test_split(h30_x,h30_t,h30_r1,h30_c1,h30_r2,h30_c2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8301e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainu_x, testu_x, trainu_t, testu_t = train_test_split(hf_x, hf_t, test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68c1b3f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train10_x=torch.from_numpy(train10_x.to_numpy()).float()\n",
    "train10_t=torch.from_numpy(train10_t.to_numpy()).float()\n",
    "\n",
    "train10_r=torch.from_numpy(train10_r.to_numpy()).float()\n",
    "train10_c=torch.from_numpy(train10_c.to_numpy()).float()\n",
    "\n",
    "trainb_x1=torch.from_numpy(trainb_x1.to_numpy()).float()\n",
    "trainb_t1=torch.from_numpy(trainb_t1.to_numpy()).float()\n",
    "trainb_x2=torch.from_numpy(trainb_x2.to_numpy()).float()\n",
    "trainb_t2=torch.from_numpy(trainb_t2.to_numpy()).float()\n",
    "\n",
    "# train20_x=torch.from_numpy(train20_x.to_numpy()).float()\n",
    "# train20_t=torch.from_numpy(train20_t.to_numpy()).float()\n",
    "train20_r=torch.from_numpy(train20_r.to_numpy()).float()\n",
    "train20_c=torch.from_numpy(train20_c.to_numpy()).float()\n",
    "\n",
    "\n",
    "train30_x=torch.from_numpy(train30_x.to_numpy()).float()\n",
    "train30_t=torch.from_numpy(train30_t.to_numpy()).float()\n",
    "train30_r1=torch.from_numpy(train30_r1.to_numpy()).float()\n",
    "train30_c1=torch.from_numpy(train30_c1.to_numpy()).float()\n",
    "train30_r2=torch.from_numpy(train30_r2.to_numpy()).float()\n",
    "train30_c2=torch.from_numpy(train30_c2.to_numpy()).float()\n",
    "\n",
    "trainu_x=torch.from_numpy(trainu_x).float()\n",
    "trainu_t=torch.from_numpy(trainu_t).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2e60ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test10_x=torch.from_numpy(test10_x.to_numpy()).float()\n",
    "test10_t=torch.from_numpy(test10_t.to_numpy()).float()\n",
    "test10_r=torch.from_numpy(test10_r.to_numpy()).float()\n",
    "test10_c=torch.from_numpy(test10_c.to_numpy()).float()\n",
    "\n",
    "testb_x1=torch.from_numpy(testb_x1.to_numpy()).float()\n",
    "testb_t1=torch.from_numpy(testb_t1.to_numpy()).float()\n",
    "testb_x2=torch.from_numpy(testb_x2.to_numpy()).float()\n",
    "testb_t2=torch.from_numpy(testb_t2.to_numpy()).float()\n",
    "\n",
    "# test20_x=torch.from_numpy(test20_x.to_numpy()).float()\n",
    "# test20_t=torch.from_numpy(test20_t.to_numpy()).float()\n",
    "test20_r=torch.from_numpy(test20_r.to_numpy()).float()\n",
    "test20_c=torch.from_numpy(test20_c.to_numpy()).float()\n",
    "\n",
    "testu_x=torch.from_numpy(testu_x).float()\n",
    "testu_t=torch.from_numpy(testu_t).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20c0aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7b860f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2, 60),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(60, 60),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(60, 60),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(60, 60),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(60, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f5e4528",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsInformedNN():\n",
    "    def __init__(self, u10_x, u10_t, u10_r, u10_c, ub_x1, ub_t1, ub_x2, ub_t2, u20_r, u20_c, uf_x, uf_t,u30_x,u30_t,u30_r1,u30_c1,u30_r2,u30_c2):\n",
    "        self.u10_x = torch.tensor(u10_x, requires_grad=True).float().to(device)\n",
    "        self.u10_t = torch.tensor(u10_t, requires_grad=True).float().to(device)\n",
    "        self.u10_r = torch.tensor(u10_r, requires_grad=True).float().to(device)\n",
    "        self.u10_c = torch.tensor(u10_c, requires_grad=True).float().to(device)\n",
    "        \n",
    "        self.ub_x1 = torch.tensor(ub_x1, requires_grad=True).float().to(device)\n",
    "        self.ub_x2 = torch.tensor(ub_x2, requires_grad=True).float().to(device)\n",
    "        self.ub_t1 = torch.tensor(ub_t1, requires_grad=True).float().to(device)\n",
    "        self.ub_t2 = torch.tensor(ub_t2, requires_grad=True).float().to(device)\n",
    "        \n",
    "#         self.u20_x = u20_x.clone().detach().requires_grad_(True).float().to(device)\n",
    "#         self.u20_t = torch.tensor(u20_t, requires_grad=True).float().to(device)\n",
    "        self.u20_r = torch.tensor(u20_r, requires_grad=True).float().to(device)\n",
    "        self.u20_c = torch.tensor(u20_c, requires_grad=True).float().to(device)\n",
    "        \n",
    "        self.u30_x = torch.tensor(u30_x, requires_grad=True).float().to(device)\n",
    "        self.u30_t = torch.tensor(u30_t, requires_grad=True).float().to(device)\n",
    "        self.u30_r1 = torch.tensor(u30_r1, requires_grad=True).float().to(device)\n",
    "        self.u30_c1 = torch.tensor(u30_c1, requires_grad=True).float().to(device)\n",
    "        self.u30_r2 = torch.tensor(u30_r2, requires_grad=True).float().to(device)\n",
    "        self.u30_c2 = torch.tensor(u30_c2, requires_grad=True).float().to(device)\n",
    "      \n",
    "        \n",
    "        self.uf_x = torch.tensor(uf_x,requires_grad=True).float().to(device)\n",
    "        self.uf_t = torch.tensor(uf_t,requires_grad=True).float().to(device)\n",
    "        \n",
    "        self.lambda_1 = torch.tensor([0.8], requires_grad=True).to(device)\n",
    "        self.lambda_1 = torch.nn.Parameter(self.lambda_1)\n",
    "        \n",
    "        self.lambda_2 = torch.tensor([2.2], requires_grad=True).to(device)\n",
    "        self.lambda_2 = torch.nn.Parameter(self.lambda_2)\n",
    "        \n",
    "        self.dnn = DNN().to(device)\n",
    "        self.optimizer = torch.optim.Adam([\n",
    "            {'params':self.dnn.parameters()},\n",
    "            {'params': [self.lambda_1], 'lr': 0.0004},\n",
    "            {'params': [self.lambda_2], 'lr': 0.0002}\n",
    "        ],lr=0.006 )\n",
    "        \n",
    "        self.iter = 0\n",
    "    \n",
    "        self.losshistory=[]\n",
    "    def net_u(self, x, t):  \n",
    "        u1 = torch.unsqueeze(self.dnn(torch.cat([x, t], dim=1))[:,0],1)\n",
    "        v1 = torch.unsqueeze(self.dnn(torch.cat([x, t], dim=1))[:,1],1)\n",
    "        u2 = torch.unsqueeze(self.dnn(torch.cat([x, t], dim=1))[:,2],1)\n",
    "        v2 = torch.unsqueeze(self.dnn(torch.cat([x, t], dim=1))[:,3],1)\n",
    "        return u1, v1, u2, v2\n",
    "\n",
    "    \n",
    "    def net_f(self, x, t):\n",
    "        \"\"\" The pytorch autograd version of calculating residual \"\"\"\n",
    "        beta=1\n",
    "        lambda_1 = self.lambda_1\n",
    "        lambda_2 = self.lambda_2\n",
    "        lambda_3 = -1\n",
    "        lambda_4 = 0\n",
    "        u1, v1,u2, v2= self.net_u(x, t)\n",
    "        \n",
    "        u1_t = torch.autograd.grad(\n",
    "            u1, t, \n",
    "            grad_outputs=torch.ones_like(u1),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        u1_x = torch.autograd.grad(\n",
    "            u1, x, \n",
    "            grad_outputs=torch.ones_like(u1),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        u1_xx = torch.autograd.grad(\n",
    "            u1_x, x, \n",
    "            grad_outputs=torch.ones_like(u1_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        v1_t = torch.autograd.grad(\n",
    "            v1, t, \n",
    "            grad_outputs=torch.ones_like(v1),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        v1_x = torch.autograd.grad(\n",
    "            v1, x, \n",
    "            grad_outputs=torch.ones_like(v1),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        v1_xx = torch.autograd.grad(\n",
    "            v1_x, x, \n",
    "            grad_outputs=torch.ones_like(v1_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        \n",
    "        u2_t = torch.autograd.grad(\n",
    "            u2, t, \n",
    "            grad_outputs=torch.ones_like(u2),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        u2_x = torch.autograd.grad(\n",
    "            u2, x, \n",
    "            grad_outputs=torch.ones_like(u2),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        u2_xx = torch.autograd.grad(\n",
    "            u2_x, x, \n",
    "            grad_outputs=torch.ones_like(u2_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        v2_t = torch.autograd.grad(\n",
    "            v2, t, \n",
    "            grad_outputs=torch.ones_like(v2),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        v2_x = torch.autograd.grad(\n",
    "            v2, x, \n",
    "            grad_outputs=torch.ones_like(v2),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        v2_xx = torch.autograd.grad(\n",
    "            v2_x, x, \n",
    "            grad_outputs=torch.ones_like(v2_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        f_u1 = (\n",
    "            v1_t + u1_xx\n",
    "        + lambda_1*u1*(u1**2 + v1**2) + lambda_2*u1*(u2**2 + v2**2) + lambda_3*(u1*(u2**2 - v2**2) + 2*u2*v1*v2) + lambda_4*(u2*(u1**2 - v1**2) + 2*u1*v1*v2)\n",
    "    )\n",
    "\n",
    "        f_v1 = (\n",
    "                -u1_t + v1_xx\n",
    "            + lambda_1*v1*(u1**2 + v1**2) + lambda_2*v1*(u2**2 + v2**2) - lambda_3*(v1*(u2**2 - v2**2) - 2*u1*u2*v2) - lambda_4*(v2*(u1**2 - v1**2) - 2*u1*u2*v1)\n",
    "        )\n",
    "\n",
    "        f_u2 = (\n",
    "                v2_t + beta*u2_xx\n",
    "            + lambda_1*u2*(u2**2 + v2**2) + lambda_2*u2*(u1**2 + v1**2) + lambda_3*(u2*(u1**2 - v1**2) + 2*u1*v2*v1) + lambda_4*(u1*(u2**2 - v2**2) + 2*u2*v2*v1)\n",
    "        )\n",
    "\n",
    "        f_v2 = (\n",
    "                -u2_t + beta*v2_xx\n",
    "            + lambda_1*v2*(u2**2 + v2**2) + lambda_2*v2*(u1**2 + v1**2) - lambda_3*(v2*(u1**2 - v1**2) - 2*u2*u1*v1) - lambda_4*(v1*(u2**2 - v2**2) - 2*u2*u1*v2)\n",
    "        )\n",
    "        a=u1_x\n",
    "        b=v1_x\n",
    "        c=u2_x\n",
    "        d=v2_x\n",
    "        return f_u1, f_v1, f_u2, f_v2, a, b, c, d\n",
    "     \n",
    "    def loss_func(self):\n",
    "        for self.iter in tqdm(range(50000)):\n",
    "            torch.cuda.empty_cache()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            u10_pred, v10_pred, u20_pred, v20_pred = self.net_u(self.u10_x,self.u10_t)\n",
    "            u30_pred1, v30_pred1, u30_pred2, v30_pred2 = self.net_u(self.u30_x,self.u30_t)\n",
    "            u1b_pred1, v1b_pred1, u2b_pred1, v2b_pred1 = self.net_u(self.ub_x1,self.ub_t1)\n",
    "            u1b_pred2, v1b_pred2, u2b_pred2, v2b_pred2 = self .net_u(self.ub_x2,self.ub_t2)\n",
    "            \n",
    "            \n",
    "            a1,b1,c1,d1,u1bx_pred1, v1bx_pred1,u2bx_pred1, v2bx_pred1 = self.net_f(self.ub_x1,self.ub_t1)\n",
    "            a2,b2,c2,d2,u1bx_pred2, v1bx_pred2,u2bx_pred2, v2bx_pred2 = self.net_f(self.ub_x2,self.ub_t2)\n",
    "            \n",
    "            f_predu1, f_predv1, f_predu2, f_predv2,a1,b1,c1,d1 = self.net_f(self.uf_x,self.uf_t)\n",
    "            \n",
    "            loss_u0 = torch.mean((self.u10_r - u10_pred) ** 2)+torch.mean((self.u10_c - v10_pred) ** 2)+torch.mean((self.u20_r - u20_pred) ** 2)+torch.mean((self.u20_c - v20_pred) ** 2)\n",
    "            loss_ub = torch.mean((u1b_pred1 - u1b_pred2) ** 2)+torch.mean((v1b_pred1 - v1b_pred2) ** 2)+torch.mean((u2b_pred1 - u2b_pred2) ** 2)+torch.mean((v2b_pred1 - v2b_pred2) ** 2)\n",
    "            loss_ubx = torch.mean((u1bx_pred1 - u1bx_pred2) ** 2)+torch.mean((v1bx_pred1 - v1bx_pred2) ** 2)+torch.mean((u2bx_pred1 - u2bx_pred2) ** 2)+torch.mean((v2bx_pred1 - v2bx_pred2) ** 2)\n",
    "            loss_f = torch.mean(f_predu1 ** 2)+torch.mean(f_predv1 ** 2)+torch.mean(f_predu2 ** 2)+torch.mean(f_predv2 ** 2)\n",
    "            loss_u1=torch.mean((self.u30_r1 - u30_pred1) ** 2)+torch.mean((self.u30_c1 - v30_pred1) ** 2)+torch.mean((self.u30_r2 - u30_pred2) ** 2)+torch.mean((self.u30_c2 - v30_pred2) ** 2)\n",
    "            \n",
    "            loss = loss_f+loss_u0 + loss_ub + loss_ubx+loss_u1\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            self.losshistory.append(loss.clone().detach().cpu())\n",
    "            \n",
    "            self.iter += 1\n",
    "            with torch.no_grad():\n",
    "                if self.iter % 500 == 0:\n",
    "                    print('Iter %d, Loss: %.5e, Loss_u0: %.5e, Loss_ub: %.5e, Loss_ubx: %.5e, Loss_f: %.5e, Loss_u1: %.5e, lambda1: %.5e, lambda2: %.5e' % (self.iter, loss.item(), loss_u0.item(), loss_ub.item(), loss_ubx.item(), loss_f.item(), loss_u1.item(), self.lambda_1,self.lambda_2))\n",
    "        return float(loss)\n",
    "        \n",
    " \n",
    "    def train(self):\n",
    "        self.dnn.train()\n",
    "                \n",
    "        # Backward and optimize\n",
    "        self.optimizer.step(self.loss_func)\n",
    "        \n",
    "    def predict1(self, X, Y):\n",
    "        x = torch.tensor(X, requires_grad=True).float().to(device)\n",
    "        t = torch.tensor(Y, requires_grad=True).float().to(device)\n",
    "\n",
    "        self.dnn.eval()\n",
    "        u1, v1 , u2, v2= self.net_u(x, t)\n",
    "        u1 = u1.detach().cpu().numpy()\n",
    "        v1 = v1.detach().cpu().numpy()\n",
    "        u2 = u2.detach().cpu().numpy()\n",
    "        v2 = v2.detach().cpu().numpy()\n",
    "        return u1, v1, u2, v2\n",
    "    \n",
    "    def predict2(self, X, Y):\n",
    "        x = torch.tensor(X, requires_grad=True).float().to(device)\n",
    "        t = torch.tensor(Y, requires_grad=True).float().to(device)\n",
    "\n",
    "        self.dnn.eval()\n",
    "        f1, f2, f3, f4, a, b, c, d = self.net_f(x, t)\n",
    "        f1 = f1.detach().cpu().numpy()\n",
    "        f2 = f2.detach().cpu().numpy()\n",
    "        f3 = f3.detach().cpu().numpy()\n",
    "        f4 = f4.detach().cpu().numpy()\n",
    "        return  f1, f2, f3, f4, a, b, c, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08905a55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_12224\\3908834773.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.u10_x = torch.tensor(u10_x, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_12224\\3908834773.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.u10_t = torch.tensor(u10_t, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_12224\\3908834773.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.u10_r = torch.tensor(u10_r, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_12224\\3908834773.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.u10_c = torch.tensor(u10_c, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_12224\\3908834773.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.ub_x1 = torch.tensor(ub_x1, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_12224\\3908834773.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.ub_x2 = torch.tensor(ub_x2, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_12224\\3908834773.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.ub_t1 = torch.tensor(ub_t1, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_12224\\3908834773.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.ub_t2 = torch.tensor(ub_t2, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_12224\\3908834773.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.u20_r = torch.tensor(u20_r, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_12224\\3908834773.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.u20_c = torch.tensor(u20_c, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_12224\\3908834773.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.u30_x = torch.tensor(u30_x, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_12224\\3908834773.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.u30_t = torch.tensor(u30_t, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_12224\\3908834773.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.u30_r1 = torch.tensor(u30_r1, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_12224\\3908834773.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.u30_c1 = torch.tensor(u30_c1, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_12224\\3908834773.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.u30_r2 = torch.tensor(u30_r2, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_12224\\3908834773.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.u30_c2 = torch.tensor(u30_c2, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_12224\\3908834773.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.uf_x = torch.tensor(uf_x,requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_12224\\3908834773.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.uf_t = torch.tensor(uf_t,requires_grad=True).float().to(device)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = PhysicsInformedNN(train10_x, train10_t, train10_r, train10_c, \n",
    "                          trainb_x1, trainb_t1, trainb_x2, trainb_t2,\n",
    "                        train20_r, train20_c, trainu_x, trainu_t,\n",
    "                         train30_x,train30_t, train30_r1, train30_c1,train30_r2,train30_c2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7626fd4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 501/50000 [00:58<1:39:16,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 500, Loss: 1.32010e-01, Loss_u0: 6.41050e-03, Loss_ub: 6.23091e-05, Loss_ubx: 3.30716e-05, Loss_f: 4.81624e-02, Loss_u1: 7.73420e-02, lambda1: 9.35743e-01, lambda2: 2.22736e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1002/50000 [01:56<1:29:52,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1000, Loss: 9.15918e-02, Loss_u0: 3.70193e-03, Loss_ub: 1.46510e-05, Loss_ubx: 1.94656e-05, Loss_f: 2.49596e-02, Loss_u1: 6.28961e-02, lambda1: 9.23743e-01, lambda2: 2.21043e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1501/50000 [02:53<1:34:03,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1500, Loss: 7.29891e-02, Loss_u0: 2.95640e-03, Loss_ub: 1.81081e-05, Loss_ubx: 8.73527e-06, Loss_f: 1.78983e-02, Loss_u1: 5.21076e-02, lambda1: 9.14050e-01, lambda2: 2.20181e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2001/50000 [03:51<1:34:32,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2000, Loss: 6.83631e-02, Loss_u0: 1.98391e-03, Loss_ub: 1.26374e-05, Loss_ubx: 1.63759e-05, Loss_f: 1.64885e-02, Loss_u1: 4.98617e-02, lambda1: 9.09488e-01, lambda2: 2.19509e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2501/50000 [04:49<1:34:40,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2500, Loss: 7.07092e-02, Loss_u0: 1.95700e-03, Loss_ub: 5.74566e-04, Loss_ubx: 1.51454e-05, Loss_f: 1.97355e-02, Loss_u1: 4.84270e-02, lambda1: 9.02632e-01, lambda2: 2.18773e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3001/50000 [05:46<1:30:42,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3000, Loss: 7.18886e-02, Loss_u0: 2.22163e-03, Loss_ub: 2.73164e-05, Loss_ubx: 1.69481e-05, Loss_f: 1.76140e-02, Loss_u1: 5.20087e-02, lambda1: 9.07099e-01, lambda2: 2.18466e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 3501/50000 [06:44<1:31:38,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3500, Loss: 6.17812e-02, Loss_u0: 1.59812e-03, Loss_ub: 2.09392e-05, Loss_ubx: 1.26338e-05, Loss_f: 1.48063e-02, Loss_u1: 4.53432e-02, lambda1: 9.01816e-01, lambda2: 2.17998e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4001/50000 [07:42<1:29:00,  8.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4000, Loss: 9.69704e-02, Loss_u0: 4.48347e-03, Loss_ub: 2.88394e-05, Loss_ubx: 2.40186e-05, Loss_f: 2.42452e-02, Loss_u1: 6.81889e-02, lambda1: 9.23058e-01, lambda2: 2.17525e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 4501/50000 [08:40<1:30:45,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4500, Loss: 7.19880e-02, Loss_u0: 2.53488e-03, Loss_ub: 3.70942e-05, Loss_ubx: 1.64291e-05, Loss_f: 1.73587e-02, Loss_u1: 5.20409e-02, lambda1: 9.16835e-01, lambda2: 2.16528e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5001/50000 [09:37<1:26:30,  8.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 5000, Loss: 9.09645e-02, Loss_u0: 3.20342e-03, Loss_ub: 3.05551e-05, Loss_ubx: 2.71968e-05, Loss_f: 2.19887e-02, Loss_u1: 6.57147e-02, lambda1: 9.23234e-01, lambda2: 2.15979e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 5501/50000 [10:35<1:24:08,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 5500, Loss: 7.24655e-02, Loss_u0: 2.49597e-03, Loss_ub: 1.08637e-05, Loss_ubx: 1.50597e-05, Loss_f: 1.81870e-02, Loss_u1: 5.17566e-02, lambda1: 9.21291e-01, lambda2: 2.15380e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6001/50000 [11:33<1:34:03,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 6000, Loss: 7.17694e-02, Loss_u0: 2.20265e-03, Loss_ub: 1.84972e-05, Loss_ubx: 8.79438e-06, Loss_f: 1.46663e-02, Loss_u1: 5.48731e-02, lambda1: 9.18450e-01, lambda2: 2.15013e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 6501/50000 [12:33<1:27:38,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 6500, Loss: 6.18758e-02, Loss_u0: 1.50316e-03, Loss_ub: 8.23941e-06, Loss_ubx: 6.28277e-06, Loss_f: 1.52350e-02, Loss_u1: 4.51232e-02, lambda1: 9.10450e-01, lambda2: 2.14514e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7001/50000 [13:31<1:25:58,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 7000, Loss: 5.23348e-02, Loss_u0: 1.14851e-03, Loss_ub: 9.56599e-06, Loss_ubx: 8.57478e-06, Loss_f: 1.09267e-02, Loss_u1: 4.02415e-02, lambda1: 8.98518e-01, lambda2: 2.13816e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 7501/50000 [14:29<1:21:13,  8.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 7500, Loss: 8.38127e-02, Loss_u0: 3.08553e-03, Loss_ub: 4.85390e-05, Loss_ubx: 1.40197e-05, Loss_f: 1.86300e-02, Loss_u1: 6.20346e-02, lambda1: 9.22222e-01, lambda2: 2.13636e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8001/50000 [15:26<1:19:03,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 8000, Loss: 6.19071e-02, Loss_u0: 1.09704e-03, Loss_ub: 9.69324e-06, Loss_ubx: 1.03742e-05, Loss_f: 1.46298e-02, Loss_u1: 4.61602e-02, lambda1: 9.05029e-01, lambda2: 2.12486e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 8501/50000 [16:24<1:18:53,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 8500, Loss: 4.95963e-02, Loss_u0: 1.16913e-03, Loss_ub: 4.52778e-06, Loss_ubx: 8.63555e-06, Loss_f: 1.20138e-02, Loss_u1: 3.64002e-02, lambda1: 8.94015e-01, lambda2: 2.11602e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9001/50000 [17:22<1:20:32,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 9000, Loss: 9.74473e-02, Loss_u0: 3.98172e-03, Loss_ub: 1.06346e-05, Loss_ubx: 1.62389e-05, Loss_f: 2.39925e-02, Loss_u1: 6.94462e-02, lambda1: 9.59579e-01, lambda2: 2.09824e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 9501/50000 [18:19<1:16:26,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 9500, Loss: 8.11708e-02, Loss_u0: 2.91282e-03, Loss_ub: 1.45920e-05, Loss_ubx: 1.21127e-05, Loss_f: 2.00991e-02, Loss_u1: 5.81322e-02, lambda1: 9.36776e-01, lambda2: 2.08542e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10001/50000 [19:17<1:16:01,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10000, Loss: 7.78497e-02, Loss_u0: 2.76477e-03, Loss_ub: 1.06996e-05, Loss_ubx: 7.72579e-06, Loss_f: 2.03581e-02, Loss_u1: 5.47083e-02, lambda1: 9.16377e-01, lambda2: 2.07558e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 10501/50000 [20:15<1:15:50,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10500, Loss: 7.05676e-02, Loss_u0: 1.82193e-03, Loss_ub: 6.80066e-06, Loss_ubx: 6.12629e-06, Loss_f: 2.00358e-02, Loss_u1: 4.86969e-02, lambda1: 8.98796e-01, lambda2: 2.06831e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11001/50000 [21:12<1:14:14,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 11000, Loss: 6.01913e-02, Loss_u0: 1.31002e-03, Loss_ub: 7.20107e-06, Loss_ubx: 5.58831e-06, Loss_f: 1.42853e-02, Loss_u1: 4.45832e-02, lambda1: 8.86219e-01, lambda2: 2.06346e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 11501/50000 [22:10<1:12:52,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 11500, Loss: 5.83132e-02, Loss_u0: 1.45103e-03, Loss_ub: 7.08292e-06, Loss_ubx: 5.37988e-06, Loss_f: 1.23706e-02, Loss_u1: 4.44791e-02, lambda1: 8.84315e-01, lambda2: 2.06009e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12001/50000 [23:08<1:14:50,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 12000, Loss: 5.34702e-02, Loss_u0: 1.14398e-03, Loss_ub: 8.07650e-06, Loss_ubx: 4.17626e-06, Loss_f: 1.14498e-02, Loss_u1: 4.08642e-02, lambda1: 8.71998e-01, lambda2: 2.05361e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 12501/50000 [24:05<1:16:40,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 12500, Loss: 4.51416e-02, Loss_u0: 9.47734e-04, Loss_ub: 5.18503e-06, Loss_ubx: 3.84105e-06, Loss_f: 7.45849e-03, Loss_u1: 3.67264e-02, lambda1: 8.53103e-01, lambda2: 2.04331e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13001/50000 [25:03<1:11:58,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 13000, Loss: 6.52721e-02, Loss_u0: 1.80706e-03, Loss_ub: 1.46353e-05, Loss_ubx: 6.39532e-06, Loss_f: 1.17198e-02, Loss_u1: 5.17242e-02, lambda1: 8.60509e-01, lambda2: 2.04328e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 13501/50000 [26:00<1:08:03,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 13500, Loss: 6.21923e-02, Loss_u0: 1.43522e-03, Loss_ub: 1.16146e-05, Loss_ubx: 7.66521e-06, Loss_f: 1.95226e-02, Loss_u1: 4.12152e-02, lambda1: 8.51943e-01, lambda2: 2.03904e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14001/50000 [26:58<1:07:49,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 14000, Loss: 4.92008e-02, Loss_u0: 1.18391e-03, Loss_ub: 6.40931e-06, Loss_ubx: 5.07957e-06, Loss_f: 9.89102e-03, Loss_u1: 3.81144e-02, lambda1: 8.44154e-01, lambda2: 2.03349e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 14501/50000 [27:56<1:08:58,  8.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 14500, Loss: 4.62253e-02, Loss_u0: 1.12555e-03, Loss_ub: 3.39311e-06, Loss_ubx: 3.69154e-06, Loss_f: 1.08120e-02, Loss_u1: 3.42808e-02, lambda1: 8.32411e-01, lambda2: 2.02684e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15001/50000 [28:54<1:08:34,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 15000, Loss: 4.53657e-02, Loss_u0: 1.11930e-03, Loss_ub: 2.08125e-06, Loss_ubx: 2.22935e-06, Loss_f: 1.02169e-02, Loss_u1: 3.40253e-02, lambda1: 8.30667e-01, lambda2: 2.02455e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 15501/50000 [29:52<1:05:05,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 15500, Loss: 5.01944e-02, Loss_u0: 1.49248e-03, Loss_ub: 7.49326e-06, Loss_ubx: 5.64339e-06, Loss_f: 1.42048e-02, Loss_u1: 3.44839e-02, lambda1: 8.30673e-01, lambda2: 2.02070e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16001/50000 [30:50<1:07:29,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 16000, Loss: 4.44562e-02, Loss_u0: 1.09190e-03, Loss_ub: 1.56952e-05, Loss_ubx: 1.02096e-05, Loss_f: 1.23964e-02, Loss_u1: 3.09419e-02, lambda1: 8.21492e-01, lambda2: 2.01538e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 16501/50000 [31:48<1:07:09,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 16500, Loss: 3.73029e-02, Loss_u0: 9.39316e-04, Loss_ub: 7.10057e-06, Loss_ubx: 7.55829e-06, Loss_f: 8.05872e-03, Loss_u1: 2.82902e-02, lambda1: 8.11544e-01, lambda2: 2.01074e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17001/50000 [32:45<1:04:46,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 17000, Loss: 6.95003e-02, Loss_u0: 1.96741e-03, Loss_ub: 3.95626e-06, Loss_ubx: 2.61320e-06, Loss_f: 1.60288e-02, Loss_u1: 5.14975e-02, lambda1: 8.84388e-01, lambda2: 2.03796e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 17501/50000 [33:43<1:03:56,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 17500, Loss: 4.96121e-02, Loss_u0: 1.14237e-03, Loss_ub: 1.99074e-06, Loss_ubx: 1.12911e-06, Loss_f: 1.40470e-02, Loss_u1: 3.44197e-02, lambda1: 8.94944e-01, lambda2: 2.04065e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18001/50000 [34:41<59:25,  8.97it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 18000, Loss: 3.78203e-02, Loss_u0: 9.47330e-04, Loss_ub: 5.23283e-07, Loss_ubx: 3.01507e-07, Loss_f: 8.08052e-03, Loss_u1: 2.87916e-02, lambda1: 8.84401e-01, lambda2: 2.03627e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 18501/50000 [35:38<1:00:05,  8.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 18500, Loss: 3.26277e-02, Loss_u0: 7.38833e-04, Loss_ub: 4.89788e-07, Loss_ubx: 7.53148e-07, Loss_f: 6.04621e-03, Loss_u1: 2.58414e-02, lambda1: 8.71639e-01, lambda2: 2.02850e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19001/50000 [36:36<59:06,  8.74it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 19000, Loss: 3.12812e-02, Loss_u0: 8.12673e-04, Loss_ub: 2.14504e-06, Loss_ubx: 2.09076e-06, Loss_f: 6.01087e-03, Loss_u1: 2.44534e-02, lambda1: 8.59019e-01, lambda2: 2.01923e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 19501/50000 [37:33<56:45,  8.96it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 19500, Loss: 1.94602e-01, Loss_u0: 5.03206e-03, Loss_ub: 8.67500e-06, Loss_ubx: 3.06604e-07, Loss_f: 3.45973e-02, Loss_u1: 1.54964e-01, lambda1: 8.89075e-01, lambda2: 2.03780e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20001/50000 [38:31<58:35,  8.53it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20000, Loss: 1.37085e-01, Loss_u0: 2.96292e-03, Loss_ub: 4.11193e-06, Loss_ubx: 6.30355e-07, Loss_f: 2.85288e-02, Loss_u1: 1.05588e-01, lambda1: 9.52685e-01, lambda2: 2.06385e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 20501/50000 [39:29<57:07,  8.61it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20500, Loss: 1.08400e-01, Loss_u0: 2.68844e-03, Loss_ub: 1.49419e-06, Loss_ubx: 8.69231e-07, Loss_f: 2.38879e-02, Loss_u1: 8.18209e-02, lambda1: 1.04297e+00, lambda2: 2.09834e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21001/50000 [40:26<56:54,  8.49it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 21000, Loss: 9.57531e-02, Loss_u0: 3.54210e-03, Loss_ub: 2.66230e-06, Loss_ubx: 6.40201e-07, Loss_f: 2.29751e-02, Loss_u1: 6.92326e-02, lambda1: 1.11151e+00, lambda2: 2.12329e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 21501/50000 [41:24<56:37,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 21500, Loss: 8.63725e-02, Loss_u0: 2.36312e-03, Loss_ub: 1.53306e-06, Loss_ubx: 3.94947e-07, Loss_f: 2.16828e-02, Loss_u1: 6.23247e-02, lambda1: 1.13950e+00, lambda2: 2.13142e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22001/50000 [42:21<53:40,  8.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 22000, Loss: 7.33811e-02, Loss_u0: 1.65507e-03, Loss_ub: 1.49955e-06, Loss_ubx: 1.23445e-07, Loss_f: 1.61037e-02, Loss_u1: 5.56207e-02, lambda1: 1.13900e+00, lambda2: 2.12902e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 22501/50000 [43:19<52:09,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 22500, Loss: 6.41044e-02, Loss_u0: 1.24187e-03, Loss_ub: 1.26653e-06, Loss_ubx: 4.08973e-07, Loss_f: 1.46361e-02, Loss_u1: 4.82248e-02, lambda1: 1.12486e+00, lambda2: 2.12186e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23001/50000 [44:18<54:26,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 23000, Loss: 6.01137e-02, Loss_u0: 1.38074e-03, Loss_ub: 1.54230e-06, Loss_ubx: 1.00999e-06, Loss_f: 1.35728e-02, Loss_u1: 4.51576e-02, lambda1: 1.10395e+00, lambda2: 2.11113e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 23501/50000 [45:16<51:45,  8.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 23500, Loss: 5.58596e-02, Loss_u0: 1.20056e-03, Loss_ub: 2.57078e-06, Loss_ubx: 3.02736e-06, Loss_f: 1.11739e-02, Loss_u1: 4.34796e-02, lambda1: 1.07800e+00, lambda2: 2.09787e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24001/50000 [46:14<53:16,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 24000, Loss: 7.52744e-02, Loss_u0: 1.61463e-03, Loss_ub: 2.26277e-06, Loss_ubx: 1.72586e-06, Loss_f: 1.74973e-02, Loss_u1: 5.61585e-02, lambda1: 1.06779e+00, lambda2: 2.09373e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 24501/50000 [47:12<47:09,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 24500, Loss: 6.67000e-02, Loss_u0: 1.46157e-03, Loss_ub: 1.24406e-06, Loss_ubx: 1.31338e-06, Loss_f: 1.57413e-02, Loss_u1: 4.94945e-02, lambda1: 1.05784e+00, lambda2: 2.08752e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25001/50000 [48:11<47:02,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 25000, Loss: 6.37144e-02, Loss_u0: 1.68131e-03, Loss_ub: 9.83843e-07, Loss_ubx: 6.27987e-07, Loss_f: 1.57828e-02, Loss_u1: 4.62487e-02, lambda1: 1.04161e+00, lambda2: 2.07862e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 25501/50000 [49:08<46:00,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 25500, Loss: 6.17344e-02, Loss_u0: 1.47222e-03, Loss_ub: 4.77996e-07, Loss_ubx: 1.88396e-07, Loss_f: 1.62193e-02, Loss_u1: 4.40422e-02, lambda1: 1.02536e+00, lambda2: 2.06987e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26001/50000 [50:06<47:11,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 26000, Loss: 6.23752e-02, Loss_u0: 3.02531e-03, Loss_ub: 4.48073e-07, Loss_ubx: 4.08947e-07, Loss_f: 1.83268e-02, Loss_u1: 4.10223e-02, lambda1: 1.00881e+00, lambda2: 2.06125e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 26501/50000 [51:05<46:33,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 26500, Loss: 5.12469e-02, Loss_u0: 1.48547e-03, Loss_ub: 9.41144e-07, Loss_ubx: 4.64764e-07, Loss_f: 1.20752e-02, Loss_u1: 3.76848e-02, lambda1: 9.92077e-01, lambda2: 2.05202e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27001/50000 [52:03<45:04,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 27000, Loss: 4.71644e-02, Loss_u0: 1.29221e-03, Loss_ub: 2.31948e-06, Loss_ubx: 7.74499e-07, Loss_f: 1.02792e-02, Loss_u1: 3.55899e-02, lambda1: 9.74442e-01, lambda2: 2.04278e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 27501/50000 [53:01<42:34,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 27500, Loss: 4.58280e-02, Loss_u0: 1.21187e-03, Loss_ub: 1.32348e-06, Loss_ubx: 5.69776e-07, Loss_f: 9.76426e-03, Loss_u1: 3.48500e-02, lambda1: 9.56873e-01, lambda2: 2.03319e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28001/50000 [53:58<48:51,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 28000, Loss: 4.43879e-02, Loss_u0: 1.09025e-03, Loss_ub: 4.93945e-07, Loss_ubx: 3.59416e-07, Loss_f: 9.64844e-03, Loss_u1: 3.36484e-02, lambda1: 9.40411e-01, lambda2: 2.02372e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 28501/50000 [54:56<41:02,  8.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 28500, Loss: 4.16993e-02, Loss_u0: 1.05317e-03, Loss_ub: 2.51347e-07, Loss_ubx: 1.90719e-07, Loss_f: 8.60103e-03, Loss_u1: 3.20447e-02, lambda1: 9.28315e-01, lambda2: 2.01652e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29001/50000 [55:55<40:22,  8.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 29000, Loss: 3.96459e-02, Loss_u0: 9.02114e-04, Loss_ub: 8.38359e-07, Loss_ubx: 1.91327e-07, Loss_f: 7.73412e-03, Loss_u1: 3.10087e-02, lambda1: 9.14122e-01, lambda2: 2.00898e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 29501/50000 [56:53<41:09,  8.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 29500, Loss: 4.32389e-01, Loss_u0: 1.25415e-01, Loss_ub: 4.87044e-21, Loss_ubx: 2.56006e-19, Loss_f: 2.31965e-02, Loss_u1: 2.83777e-01, lambda1: 8.97929e-01, lambda2: 2.00013e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30001/50000 [57:52<37:59,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 30000, Loss: 4.21697e-01, Loss_u0: 1.17918e-01, Loss_ub: 3.84745e-18, Loss_ubx: 7.90471e-17, Loss_f: 2.27096e-02, Loss_u1: 2.81070e-01, lambda1: 8.98028e-01, lambda2: 2.00013e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 30501/50000 [58:50<37:30,  8.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 30500, Loss: 4.19319e-01, Loss_u0: 1.13958e-01, Loss_ub: 5.65659e-21, Loss_ubx: 1.88300e-19, Loss_f: 2.36133e-02, Loss_u1: 2.81748e-01, lambda1: 8.97213e-01, lambda2: 2.00013e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31001/50000 [59:48<37:10,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 31000, Loss: 4.15761e-01, Loss_u0: 1.14432e-01, Loss_ub: 6.61744e-25, Loss_ubx: 2.90974e-23, Loss_f: 1.94878e-02, Loss_u1: 2.81841e-01, lambda1: 8.95920e-01, lambda2: 2.00013e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 31501/50000 [1:00:46<36:03,  8.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 31500, Loss: 4.08907e-01, Loss_u0: 1.11753e-01, Loss_ub: 9.92617e-25, Loss_ubx: 6.26109e-23, Loss_f: 1.63733e-02, Loss_u1: 2.80781e-01, lambda1: 8.94456e-01, lambda2: 2.00013e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32001/50000 [1:01:44<34:12,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 32000, Loss: 5.43070e-01, Loss_u0: 2.33545e-01, Loss_ub: 0.00000e+00, Loss_ubx: 1.84009e-25, Loss_f: 2.82617e-07, Loss_u1: 3.09526e-01, lambda1: 8.93635e-01, lambda2: 2.00012e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 32501/50000 [1:02:42<33:57,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 32500, Loss: 5.43065e-01, Loss_u0: 2.33555e-01, Loss_ub: 0.00000e+00, Loss_ubx: 2.55719e-25, Loss_f: 3.58795e-07, Loss_u1: 3.09509e-01, lambda1: 8.93635e-01, lambda2: 2.00012e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33001/50000 [1:03:40<32:18,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 33000, Loss: 5.43075e-01, Loss_u0: 2.33554e-01, Loss_ub: 0.00000e+00, Loss_ubx: 9.58926e-24, Loss_f: 6.04943e-08, Loss_u1: 3.09521e-01, lambda1: 8.94232e-01, lambda2: 2.00012e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 33501/50000 [1:04:38<32:32,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 33500, Loss: 5.43075e-01, Loss_u0: 2.33556e-01, Loss_ub: 0.00000e+00, Loss_ubx: 9.92911e-24, Loss_f: 4.98462e-08, Loss_u1: 3.09519e-01, lambda1: 8.94232e-01, lambda2: 2.00012e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34001/50000 [1:05:36<29:33,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 34000, Loss: 5.43075e-01, Loss_u0: 2.33556e-01, Loss_ub: 0.00000e+00, Loss_ubx: 1.03834e-23, Loss_f: 4.83456e-08, Loss_u1: 3.09519e-01, lambda1: 8.94232e-01, lambda2: 2.00012e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 34501/50000 [1:06:33<30:41,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 34500, Loss: 5.43075e-01, Loss_u0: 2.33556e-01, Loss_ub: 0.00000e+00, Loss_ubx: 1.10071e-23, Loss_f: 4.77890e-08, Loss_u1: 3.09519e-01, lambda1: 8.94232e-01, lambda2: 2.00012e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35001/50000 [1:07:31<29:21,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 35000, Loss: 5.43075e-01, Loss_u0: 2.33556e-01, Loss_ub: 0.00000e+00, Loss_ubx: 1.18880e-23, Loss_f: 4.75162e-08, Loss_u1: 3.09519e-01, lambda1: 8.94232e-01, lambda2: 2.00012e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 35449/50000 [1:08:24<28:26,  8.53it/s]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "               \n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117e3d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a73b340970>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.losshistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e027874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_21764\\1886832149.py:206: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_21764\\1886832149.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(Y, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_21764\\1886832149.py:218: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X, requires_grad=True).float().to(device)\n",
      "C:\\Users\\npofsi\\AppData\\Local\\Temp\\ipykernel_21764\\1886832149.py:219: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(Y, requires_grad=True).float().to(device)\n"
     ]
    }
   ],
   "source": [
    "u00_1, v00_1, u00_2, v00_2 = model.predict1(test10_x,test10_t)\n",
    "u11_1, v11_1, u11_2, v11_2 = model.predict1(testb_x1,testb_t1)\n",
    "u22_1, v22_1, u22_2, v22_2 = model.predict1(testb_x2,testb_t2)\n",
    "a1,b1,c1,d1, ux11_1, vx11_1, ux11_2, vx11_2 = model.predict2(testb_x1,testb_t1)\n",
    "a1,b1,c1,d1, ux22_1, vx22_1, ux22_2, vx22_2 = model.predict2(testb_x2,testb_t2)\n",
    "\n",
    "f1, f2, f3, f4,a1,b1,c1,d1 = model.predict2(testu_x,testu_t)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5c0224",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error_u0: 3.83142e-03, Error_ub: 5.26785e-07, Error_ubx: 7.66790e-08, Error_f: 6.64155e-02\n"
     ]
    }
   ],
   "source": [
    "error_u0= ((np.linalg.norm(test10_r - u00_1, 2))**2+(np.linalg.norm(test10_c - v00_1, 2))**2+(np.linalg.norm(test20_r - u00_2, 2))**2+(np.linalg.norm(test20_c - v00_2, 2))**2)/20\n",
    "error_ub= ((np.linalg.norm(u11_1 - u22_1, 2))**2+(np.linalg.norm(v11_1 - v22_1, 2))**2+(np.linalg.norm(u11_1 - u22_1, 2))**2+(np.linalg.norm(v11_1 - v22_1, 2))**2)/20\n",
    "error_ubx= (\n",
    "    (np.linalg.norm(ux11_1.cpu().detach().numpy() - ux22_1.cpu().detach().numpy(), 2))**2+\n",
    "    (np.linalg.norm(vx11_1.cpu().detach().numpy() - vx22_1.cpu().detach().numpy(), 2))**2+\n",
    "    (np.linalg.norm(ux11_2.cpu().detach().numpy() - ux22_2.cpu().detach().numpy(), 2))**2+\n",
    "    (np.linalg.norm(vx11_2.cpu().detach().numpy() - vx22_2.cpu().detach().numpy(), 2))**2)/20\n",
    "\n",
    "error_f= ((np.linalg.norm(f1, 2))**2+(np.linalg.norm(f2, 2))**2+(np.linalg.norm(f1, 2))**2+(np.linalg.norm(f2, 2))**2)/2000\n",
    "print('Error_u0: %.5e, Error_ub: %.5e, Error_ubx: %.5e, Error_f: %.5e' % (error_u0.item(), error_ub.item(), error_ubx.item(), error_f.item()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1854a589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f49206fcf84a9145e7e21228cbafa911d1ac18292303b01e865d8267a9c448f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
