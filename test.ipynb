{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f8fbd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\python.exe\n",
      "D:\\anaconda\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "print(sys.executable)\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "\n",
    "import deepxde as dde\n",
    "\n",
    "# 用于绘图\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "a = 1\n",
    "b = 2\n",
    "k_r = 1.5\n",
    "k_i = 1\n",
    "v_1 = 1\n",
    "v_2 = 1\n",
    "v_3 = 1\n",
    "c = np.log((a * a * v_1 + b * b * v_2 + a * b * v_3 + a * b * v_3) / ((2 * k_r) * (2 * k_r)))\n",
    "print(sys.executable)\n",
    "#周期性边界条件\n",
    "x_lower = -10\n",
    "x_upper = 10\n",
    "t_lower = -2\n",
    "t_upper =2\n",
    "\n",
    "# 创建 2D 域（用于绘图和输入）\n",
    "x = np.linspace(x_lower, x_upper, 512)\n",
    "t = np.linspace(t_lower, t_upper, 402)\n",
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "# 整个域变平\n",
    "X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "\n",
    "# 空间和时间域/几何（对于 deepxde 模型）\n",
    "space_domain = dde.geometry.Interval(x_lower, x_upper)\n",
    "time_domain = dde.geometry.TimeDomain(t_lower, t_upper)\n",
    "geomtime = dde.geometry.GeometryXTime(space_domain, time_domain)\n",
    "# 损失的“物理信息”部分\n",
    "\n",
    "\n",
    "def pde(x,y):\n",
    "    \"\"\"\n",
    "    INPUTS:\n",
    "        x: x[:,0] 是 x 坐标\n",
    "           x[:,1] 是 t 坐标\n",
    "        y: 网络输出，在这种情况下:\n",
    "            y[:,0] 是 u(x,t) 实部\n",
    "            y[:,1] 是 v(x,t) 虚部\n",
    "    OUTPUT:\n",
    "        标准形式的 pde，即必须为零的东西\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    u1 = y[:, 0:1]\n",
    "    v1 = y[:, 1:2]\n",
    "    u2 = y[:, 2:3]\n",
    "    v2 = y[:, 3:4]\n",
    "    \n",
    "\n",
    "    # 在'jacobian'中，i 是输出分量，j 是输入分量\n",
    "    u1_t = dde.grad.jacobian(y, x, i=0, j=1)\n",
    "    v1_t = dde.grad.jacobian(y, x, i=1, j=1)\n",
    "    u2_t = dde.grad.jacobian(y, x, i=2, j=1)\n",
    "    v2_t = dde.grad.jacobian(y, x, i=3, j=1)\n",
    "\n",
    "    u1_x = dde.grad.jacobian(y, x, i=0, j=0)\n",
    "    v1_x = dde.grad.jacobian(y, x, i=1, j=0)\n",
    "    u2_x = dde.grad.jacobian(y, x, i=2, j=0)\n",
    "    v2_x = dde.grad.jacobian(y, x, i=3, j=0)\n",
    "\n",
    "    # 在“hessian”中，i 和 j 都是输入分量。 （Hessian 原则上可以是 d^2y/dxdt、d^2y/d^2x 等）\n",
    "    # 输出组件由“组件”选择\n",
    "    u1_xx = dde.grad.hessian(y, x, component=0, i=0, j=0)\n",
    "    v1_xx = dde.grad.hessian(y, x, component=1, i=0, j=0)\n",
    "    u2_xx = dde.grad.hessian(y, x, component=2, i=0, j=0)\n",
    "    v2_xx = dde.grad.hessian(y, x, component=3, i=0, j=0)\n",
    "\n",
    "    #f_u = u_t + 0.5 * v_xx + (u ** 2 + v ** 2) * v\n",
    "    #f_v = v_t - 0.5 * u_xx - (u ** 2 + v ** 2) * u\n",
    "\n",
    "    r1=1\n",
    "    r2=2\n",
    "    r3=-1\n",
    "    r4=0\n",
    "    beta=1\n",
    "    \n",
    "    f_u1 = (\n",
    "            v1_t + u1_xx\n",
    "        + r1*u1*(u1**2 + v1**2) + r2*u1*(u2**2 + v2**2) + r3*(u1*(u2**2 - v2**2) + 2*u2*v1*v2) + r4*(u2*(u1**2 - v1**2) + 2*u1*v1*v2)\n",
    "    )\n",
    "\n",
    "    f_v1 = (\n",
    "            -u1_t + v1_xx\n",
    "        + r1*v1*(u1**2 + v1**2) + r2*v1*(u2**2 + v2**2) - r3*(v1*(u2**2 - v2**2) - 2*u1*u2*v2) - r4*(v2*(u1**2 - v1**2) - 2*u1*u2*v1)\n",
    "    )\n",
    "\n",
    "    f_u2 = (\n",
    "            v2_t + beta*u2_xx\n",
    "        + r1*u2*(u2**2 + v2**2) + r2*u2*(u1**2 + v1**2) + r3*(u2*(u1**2 - v1**2) + 2*u1*v2*v1) + r4*(u1*(u2**2 - v2**2) + 2*u2*v2*v1)\n",
    "    )\n",
    "\n",
    "    f_v2 = (\n",
    "            -u2_t + beta*v2_xx\n",
    "        + r1*v2*(u2**2 + v2**2) + r2*v2*(u1**2 + v1**2) - r3*(v2*(u1**2 - v1**2) - 2*u2*u1*v1) - r4*(v1*(u2**2 - v2**2) - 2*u2*u1*v2)\n",
    "    )\n",
    "    \n",
    "    return [\n",
    "        f_u1, f_v1, f_u2, f_v2,\n",
    "        #f_u1x, f_u1t,\n",
    "        #f_v1x, f_v1t,\n",
    "        #f_u2x, f_u2t,\n",
    "        #f_v2x, f_v2t\n",
    "    ]\n",
    " # 边界条件和初始条件\n",
    "\n",
    "# 周期性边界条件\n",
    "bc_u1_0 = dde.PeriodicBC(\n",
    "    geomtime, 0, lambda _, on_boundary: on_boundary, derivative_order=0, component=0\n",
    ")\n",
    "bc_u1_1 = dde.PeriodicBC(\n",
    "    geomtime, 0, lambda _, on_boundary: on_boundary, derivative_order=1, component=0\n",
    ")\n",
    "bc_v1_0 = dde.PeriodicBC(\n",
    "    geomtime, 0, lambda _, on_boundary: on_boundary, derivative_order=0, component=1\n",
    ")\n",
    "bc_v1_1 = dde.PeriodicBC(\n",
    "    geomtime, 0, lambda _, on_boundary: on_boundary, derivative_order=1, component=1\n",
    ")\n",
    "bc_u2_0 = dde.PeriodicBC(\n",
    "    geomtime, 0, lambda _, on_boundary: on_boundary, derivative_order=0, component=2\n",
    ")\n",
    "bc_u2_1 = dde.PeriodicBC(\n",
    "    geomtime, 0, lambda _, on_boundary: on_boundary, derivative_order=1, component=2\n",
    ")\n",
    "bc_v2_0 = dde.PeriodicBC(\n",
    "    geomtime, 0, lambda _, on_boundary: on_boundary, derivative_order=0, component=3\n",
    ")\n",
    "bc_v2_1 = dde.PeriodicBC(\n",
    "    geomtime, 0, lambda _, on_boundary: on_boundary, derivative_order=1, component=3\n",
    ")\n",
    "#(e^c=...)\n",
    "# 初始条件\n",
    "def boundary_l(x, on_boundary):\n",
    "    return on_boundary and np.isclose(x[0], -1)\n",
    "\n",
    "k1=1.5\n",
    "k2=1\n",
    "l1=1.5\n",
    "l2=-1\n",
    "nf1=0\n",
    "nf2=0\n",
    "ng1=0\n",
    "ng2=0\n",
    "k=complex(k1,-k2)\n",
    "kk=k.conjugate()\n",
    "l=complex(l1,-l2)\n",
    "ll=l.conjugate()\n",
    "nf=complex(nf1,-nf2)\n",
    "nff=nf.conjugate()\n",
    "ng=complex(ng1,-ng2)\n",
    "ngg=ng.conjugate()\n",
    "\n",
    "\n",
    "\n",
    "def init_cond_u1(x):\n",
    "    f=np.exp((0-1j)*(k**2)*x[:,1:2] + k*x[:,0:1] + nf)\n",
    "    ff=f.conjugate()\n",
    "    g=np.exp((0-1j)*(l**2)*x[:,1:2] + l*x[:,0:1] + ng)\n",
    "    gg=g.conjugate()\n",
    "    phi1=1+2*f*ff/((k+kk)**2)\n",
    "    phi2=1+2*g*gg/((l+ll)**2)\n",
    "    f1=f.real\n",
    "    f2=-f.imag\n",
    "    g1=g.real\n",
    "    g2=-g.imag\n",
    "    \n",
    "    result=f1/phi1 +g1/phi2\n",
    "    \n",
    "    \n",
    "    #result=( (1/phi1)*(np.exp(-2*k1*k2*x[:,1:2] + k1*x[:,0:1] + nf1) * np.cos((-k1**2+k2**2)*x[:,1:2] - k2*x[:,0:1] - nf2))\n",
    "     #       + (1/phi2)*(np.exp(-2*l1*l2*x[:,1:2] + l1*x[:,0:1] + ng1) * np.cos((-l1**2+l2**2)*x[:,1:2] - l2*x[:,0:1] - ng2))\n",
    "     #      )\n",
    "    print(result.shape)\n",
    "    return result\n",
    "    \n",
    "def init_cond_u2(x):\n",
    "    f=np.exp((0-1j)*(k**2)*x[:,1:2] + k*x[:,0:1] + nf)\n",
    "    ff=f.conjugate()\n",
    "    g=np.exp((0-1j)*(l**2)*x[:,1:2] + l*x[:,0:1] + ng)\n",
    "    gg=g.conjugate()\n",
    "    phi1=1+2*f*ff/((k+kk)**2)\n",
    "    phi2=1+2*g*gg/((l+ll)**2)\n",
    "    f1=f.real\n",
    "    f2=-f.imag\n",
    "    g1=g.real\n",
    "    g2=-g.imag\n",
    "    \n",
    "    result=f2/phi1 - g2/phi2\n",
    "    \n",
    "    #result=( -(1/phi1)*(np.exp(-2*k1*k2*x[:,1:2] + k1*x[:,0:1] + nf1) * np.sin((-k1**2+k2**2)*x[:,1:2] - k2*x[:,0:1] - nf2))\n",
    "     #       + (1/phi2)*(np.exp(-2*l1*l2*x[:,1:2] + l1*x[:,0:1] + ng1) * np.sin((-l1**2+l2**2)*x[:,1:2] - l2*x[:,0:1] - ng2))\n",
    "      #     )\n",
    "    return result\n",
    "\n",
    "def init_cond_v1(x):\n",
    "    f=np.exp((0-1j)*(k**2)*x[:,1:2] + k*x[:,0:1] + nf)\n",
    "    ff=f.conjugate()\n",
    "    g=np.exp((0-1j)*(l**2)*x[:,1:2] + l*x[:,0:1] + ng)\n",
    "    gg=g.conjugate()\n",
    "    phi1=1+2*f*ff/((k+kk)**2)\n",
    "    phi2=1+2*g*gg/((l+ll)**2)\n",
    "    f1=f.real\n",
    "    f2=-f.imag\n",
    "    g1=g.real\n",
    "    g2=-g.imag\n",
    "    \n",
    "    result= f2/phi1 + g2/phi2\n",
    "    \n",
    "    #result=-( (1/phi1)*(np.exp(-2*k1*k2*x[:,1:2] + k1*x[:,0:1] + nf1) * np.sin((-k1**2+k2**2)*x[:,1:2] - k2*x[:,0:1] - nf2))\n",
    "    #        + (1/phi2)*(np.exp(-2*l1*l2*x[:,1:2] + l1*x[:,0:1] + ng1) * np.sin((-l1**2+l2**2)*x[:,1:2] - l2*x[:,0:1] - ng2))\n",
    "    #       )\n",
    "    return result\n",
    "\n",
    "def init_cond_v2(x):\n",
    "    f=np.exp((0-1j)*(k**2)*x[:,1:2] + k*x[:,0:1] + nf)\n",
    "    ff=f.conjugate()\n",
    "    g=np.exp((0-1j)*(l**2)*x[:,1:2] + l*x[:,0:1] + ng)\n",
    "    gg=g.conjugate()\n",
    "    phi1=1+2*f*ff/((k+kk)**2)\n",
    "    phi2=1+2*g*gg/((l+ll)**2)\n",
    "    f1=f.real\n",
    "    f2=-f.imag\n",
    "    g1=g.real\n",
    "    g2=-g.imag\n",
    "    \n",
    "    result= -f1/phi1 +g1/phi2\n",
    "    \n",
    "    #result= ( -(1/phi1)*(np.exp(-2*k1*k2*x[:,1:2] + k1*x[:,0:1] + nf1) * np.cos((-k1**2+k2**2)*x[:,1:2] - k2*x[:,0:1] - nf2))\n",
    "    #        + (1/phi2)*(np.exp(-2*l1*l2*x[:,1:2] + l1*x[:,0:1] + ng1) * np.cos((-l1**2+l2**2)*x[:,1:2] - l2*x[:,0:1] - ng2))\n",
    "    #       )\n",
    "    return result\n",
    "\n",
    "ic_u1 = dde.IC(geomtime, init_cond_u1, lambda _, on_initial: on_initial, component=0)\n",
    "ic_v1 = dde.IC(geomtime, init_cond_v1, lambda _, on_initial: on_initial, component=1)\n",
    "ic_u2 = dde.IC(geomtime, init_cond_u2, lambda _, on_initial: on_initial, component=2)\n",
    "ic_v2 = dde.IC(geomtime, init_cond_v2, lambda _, on_initial: on_initial, component=3)\n",
    "\n",
    "data = dde.data.TimePDE(\n",
    "    geomtime,\n",
    "    pde,\n",
    "    [bc_u1_0, bc_u1_1, bc_v1_0, bc_v1_1,bc_u2_0, bc_u2_1, bc_v2_0, bc_v2_1, ic_u1, ic_v1,ic_u2, ic_v2],\n",
    "    num_domain=10000,\n",
    "    num_boundary=20,\n",
    "    num_initial=200,\n",
    "    train_distribution=\"pseudo\",\n",
    ")\n",
    "\n",
    "allow_unused=True\n",
    "# 网络架构\n",
    "net = dde.maps.FNN([2] + [100] * 5 + [4], \"silu\", \"Glorot normal\")\n",
    "\n",
    "model = dde.Model(data, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79aba169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "Building feed-forward neural network...\n",
      "'build' took 0.107141 s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86183\\AppData\\Roaming\\Python\\Python39\\site-packages\\deepxde\\nn\\tensorflow_compat_v1\\fnn.py:103: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  return tf.layers.dense(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 1)\n",
      "(200, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86183\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:437: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  nparray = values.astype(dtype.as_numpy_dtype)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madam\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMSE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40000\u001b[39m, display_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\deepxde\\utils\\internal.py:22\u001b[0m, in \u001b[0;36mtiming.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     21\u001b[0m     ts \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n\u001b[1;32m---> 22\u001b[0m     result \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     23\u001b[0m     te \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m took \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m s\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, te \u001b[38;5;241m-\u001b[39m ts))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\deepxde\\model.py:124\u001b[0m, in \u001b[0;36mModel.compile\u001b[1;34m(self, optimizer, lr, loss, metrics, decay, loss_weights, external_trainable_variables)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexternal_trainable_variables \u001b[38;5;241m=\u001b[39m external_trainable_variables\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow.compat.v1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compile_tensorflow_compat_v1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compile_tensorflow(lr, loss_fn, decay, loss_weights)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\deepxde\\model.py:177\u001b[0m, in \u001b[0;36mModel._compile_tensorflow_compat_v1\u001b[1;34m(self, lr, loss_fn, decay, loss_weights)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs_losses_train \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet\u001b[38;5;241m.\u001b[39moutputs, losses_train]\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs_losses_test \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet\u001b[38;5;241m.\u001b[39moutputs, losses_test]\n\u001b[1;32m--> 177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step \u001b[38;5;241m=\u001b[39m \u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecay\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\deepxde\\optimizers\\tensorflow_compat_v1\\optimizers.py:58\u001b[0m, in \u001b[0;36mget\u001b[1;34m(loss, optimizer, learning_rate, decay)\u001b[0m\n\u001b[0;32m     56\u001b[0m update_ops \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mget_collection(tf\u001b[38;5;241m.\u001b[39mGraphKeys\u001b[38;5;241m.\u001b[39mUPDATE_OPS)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(update_ops):\n\u001b[1;32m---> 58\u001b[0m     train_op \u001b[38;5;241m=\u001b[39m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_op\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\optimizer.py:477\u001b[0m, in \u001b[0;36mOptimizer.minimize\u001b[1;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminimize\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss, global_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, var_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    434\u001b[0m              gate_gradients\u001b[38;5;241m=\u001b[39mGATE_OP, aggregation_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    435\u001b[0m              colocate_gradients_with_ops\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    436\u001b[0m              grad_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    437\u001b[0m   \u001b[38;5;124;03m\"\"\"Add operations to minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \n\u001b[0;32m    439\u001b[0m \u001b[38;5;124;03m  This method simply combines calls `compute_gradients()` and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;124;03m  @end_compatibility\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 477\u001b[0m   grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_gradients\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m      \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgate_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgate_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m      \u001b[49m\u001b[43maggregation_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcolocate_gradients_with_ops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolocate_gradients_with_ops\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mgrad_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    483\u001b[0m   vars_with_grad \u001b[38;5;241m=\u001b[39m [v \u001b[38;5;28;01mfor\u001b[39;00m g, v \u001b[38;5;129;01min\u001b[39;00m grads_and_vars \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m    484\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vars_with_grad:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\optimizer.py:603\u001b[0m, in \u001b[0;36mOptimizer.compute_gradients\u001b[1;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[0;32m    601\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo variables to optimize.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    602\u001b[0m var_refs \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mtarget() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m processors]\n\u001b[1;32m--> 603\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mgradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradients\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_refs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_ys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgate_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgate_gradients\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mOptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGATE_OP\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggregation_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolocate_gradients_with_ops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolocate_gradients_with_ops\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gate_gradients \u001b[38;5;241m==\u001b[39m Optimizer\u001b[38;5;241m.\u001b[39mGATE_GRAPH:\n\u001b[0;32m    609\u001b[0m   grads \u001b[38;5;241m=\u001b[39m control_flow_ops\u001b[38;5;241m.\u001b[39mtuple(grads)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:165\u001b[0m, in \u001b[0;36mgradients\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# Creating the gradient graph for control flow mutates Operations.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# _mutation_lock ensures a Session.run call cannot occur between creating and\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m# mutating new ops.\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\u001b[38;5;241m.\u001b[39m_mutation_lock():\n\u001b[1;32m--> 165\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgradients_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_GradientsHelper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m      \u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_ys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolocate_gradients_with_ops\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m      \u001b[49m\u001b[43mgate_gradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maggregation_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m      \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:724\u001b[0m, in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(in_grad, ops\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     t_in\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mresource):\n\u001b[0;32m    723\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 724\u001b[0m     \u001b[43min_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_in\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    725\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m    726\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    727\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible shapes between op input and calculated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    728\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput gradient. Forward operation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Input \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    729\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Original input shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_in\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    730\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculated input gradient shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_grad\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py:830\u001b[0m, in \u001b[0;36mTensor.set_shape\u001b[1;34m(self, shape)\u001b[0m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39m_c_graph\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;28;01mas\u001b[39;00m c_graph:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 830\u001b[0m     \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_GraphSetTensorShape_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_as_tf_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munknown_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    833\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m    834\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(\"adam\", lr=1e-3, loss=\"MSE\")\n",
    "model.train(epochs=40000, display_every=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bd0d29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
